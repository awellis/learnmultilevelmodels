{
  "articles": [
    {
      "path": "about.html",
      "title": "About this blog",
      "description": "Some additional details about the blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-06-11T06:04:20+02:00"
    },
    {
      "path": "assignment-1.html",
      "title": "Assignment 1",
      "description": "Estimating means and standard deviations\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-24-2021",
      "contents": "\n\nContents\nGenerate data\n\nBefore completing this assignment, please read the brms walkthrough.\nWe fitted a gaussian model to some simple generated data. However, in the model we assumed that both groups had the same standard deviations. This assumption is not really necessary, however, as we can easily fit a model in which we allow both mean and standard deviation to vary between groups.\n\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nGenerate data\n\n\nN <- 10\n\nmean_a <- 20.0\nsigma_a <- 2.0\n\nmean_b <- 16.0\nsigma_b <- 1.5\n\nset.seed(12)\nd <- tibble(A = rnorm(N, mean_a, sigma_a),\n            B = rnorm(N, mean_b, sigma_b))\nd <- d |>\n  pivot_longer(everything(), names_to = \"group\",\n                values_to = \"score\") |> \n  mutate(group = as_factor(group)) |> \n  arrange(group)\n\n\n\nbrms allows us easily fit both the main parameter (in this case the mean), as well as further distributional parameters. We simply need to wrap the formula in the bf() function. Therefore, instead of the formula score ~ group we can use this bf(score ~ group, sigma ~ group).\n\n\nscore ~ group\n\n\n\nCan be replaced with:\n\n\nbf(score ~ group, sigma ~ group)\n\n\n\n\nPerform the steps described in the walkthrough, but this time for the model that allows both \\(\\mu\\) and \\(\\sigma\\) to vary. Does this model perform well? Are you able to recover the true parameter values?\nNOTE: The standard deviation must be positive; therefore we are predicting log(sigma) with our linear predictor. To recover the parameter on the original scale, you need to use the inverse function, which is the exponential function exp().\nTry it out; if you get stuck, you can always ask questions on Zulip.\n\n\n\nShow code\n\nget_prior(bf(score ~ group, sigma ~ group),\n          data = d)\n\n\n                   prior     class   coef group resp  dpar nlpar\n                  (flat)         b                              \n                  (flat)         b groupB                       \n student_t(3, 16.9, 2.5) Intercept                              \n                  (flat)         b                   sigma      \n                  (flat)         b groupB            sigma      \n    student_t(3, 0, 2.5) Intercept                   sigma      \n bound       source\n            default\n       (vectorized)\n            default\n       (vectorized)\n       (vectorized)\n            default\n\n\n\nShow code\n\nm3 <- brm(bf(score ~ group, sigma ~ group),\n          prior = prior(normal(0, 4), class = b),\n          data = d, \n          file = \"models/m3\")\n\n\n\n\n\nShow code\n\nconditional_effects(m3)\n\n\n\n\n\n\nShow code\n\npp_check(m3)\n\n\n\n\n\n\nShow code\n\npp_check(m3, type = \"dens_overlay_grouped\", group = \"group\")\n\n\n\n\n\n\n\n",
      "last_modified": "2021-06-11T06:04:27+02:00"
    },
    {
      "path": "assignment-2.html",
      "title": "Assignment 2",
      "description": "Parameter estimation in clustered data\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\n\n\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nExercise 1\nUse the simulate_treament() function to generate data. Vary the parameter settings, and then attempt to recover the known parameters using brm().\nExercise 2\nUse the simulate_treament() function to generate data. Give your data to a colleague and they will give you theirs in return. Try to recover the (unknown to you) parameters using brm().\nExercise 3\nLoad the dataset sleepstudy from the lme4 package. These are data from a sleep deprivation study, in which the average reaction time per day (in milliseconds) was recorded.\nHave a look at the data, and then try to estimate the effect of day on reaction time.\n\nIt’s always a good idea to plot the data before you do anything else.\n\n\n\nlibrary(lme4)\nglimpse(sleepstudy)\n\n\nRows: 180\nColumns: 3\n$ Reaction <dbl> 249.5600, 258.7047, 250.8006, 321.4398, 356.8519, 4…\n$ Days     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, …\n$ Subject  <fct> 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 3…\n\n\n\n\n",
      "last_modified": "2021-06-11T06:04:28+02:00"
    },
    {
      "path": "assignment-3.html",
      "title": "Assignment 3",
      "description": "Pupil popularity and extraversion\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nDownload data\nIntercept-only model\nFirst level predictors\nSecond level predictors\nCross-level interaction\n\n\n\nShow code\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nWe’ll look at a dataset containing popularity ratings (given by classmates) and various personal characteristics of pupils in different classes. The data are available from thecompanion website of a book on multilevel analysis (“Multilevel Analysis: Techniques and Applications, Third Edition” n.d.). The code used here borrows heavily from one of the authors’ website.\nDownload data\n\n\nShow code\n\npopularity <- haven::read_sav(file = \"https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav?raw=true\")\n\n\n\n\n\nShow code\n\npopularity <- popularity |> \n  select(-starts_with(\"Z\"), -Cextrav, - Ctexp, -Csex) |> \n  mutate(sex = haven::as_factor(sex),\n         pupil = as_factor(pupil),\n         class = as_factor(class))\n\npopularity\n\n\n# A tibble: 2,000 x 7\n   pupil class extrav sex    texp popular popteach\n   <fct> <fct>  <dbl> <fct> <dbl>   <dbl>    <dbl>\n 1 1     1          5 girl     24     6.3        6\n 2 2     1          7 boy      24     4.9        5\n 3 3     1          4 girl     24     5.3        6\n 4 4     1          3 girl     24     4.7        5\n 5 5     1          5 girl     24     6          6\n 6 6     1          4 boy      24     4.7        5\n 7 7     1          5 boy      24     5.9        5\n 8 8     1          4 boy      24     4.2        5\n 9 9     1          5 boy      24     5.2        5\n10 10    1          5 boy      24     3.9        3\n# … with 1,990 more rows\n\nThe variables are\n- pupil: ID   \n- class: which class are pupils in?\n- extrav: extraversion score\n- sex: girl or boy\n- texp: teacher experience\n- popular: popularity rating\n- popteach: teacher popularity\n- Zextrav: z-transformed extraversion score           \nYou want to predict pupils’ popularity using their extraversion, gender and teacher experience.\n\nIt is important to consider which the predictor variables are at. extrav and sex are level-1 predictors, which means they are variables which vary with each observation (here this means by pupils), whereas texp is a level-2 predictor—this does not vary by observation, but by class. In other words, teacher experience is an attribute of class.\n\n\nYou should center the predictor variables.\nHow many pupils are there per class?\n\n\n\nShow code\n\nglimpse(popularity)\n\n\nRows: 2,000\nColumns: 7\n$ pupil    <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ class    <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ extrav   <dbl> 5, 7, 4, 3, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 6, 4, …\n$ sex      <fct> girl, boy, girl, girl, girl, boy, boy, boy, boy, bo…\n$ texp     <dbl> 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,…\n$ popular  <dbl> 6.3, 4.9, 5.3, 4.7, 6.0, 4.7, 5.9, 4.2, 5.2, 3.9, 5…\n$ popteach <dbl> 6, 5, 6, 5, 6, 5, 5, 5, 5, 3, 5, 5, 5, 6, 5, 5, 2, …\n\n\n\nShow code\n\npopularity <- popularity |> \n  mutate(teacher_exp = texp - mean(texp))\n\n\n\n\n\nShow code\n\npopularity |> \n  count(class)\n\n\n# A tibble: 100 x 2\n   class     n\n   <fct> <int>\n 1 1        20\n 2 2        20\n 3 3        18\n 4 4        23\n 5 5        21\n 6 6        20\n 7 7        21\n 8 8        20\n 9 9        20\n10 10       24\n# … with 90 more rows\n\n\n\nShow code\n\npopularity |> \n  group_by(class) |> \n  n_groups()\n\n\n[1] 100\n\nWe can plot the data, without taking into account the hierarchical structure.\n\n\nShow code\n\npopularity |> \n  ggplot(aes(x = extrav,\n           y = popular,\n           color = class,\n           group = class)) + \n  geom_point(size     = 1.2,\n             alpha    = .8,\n             position = \"jitter\") +\n  theme(legend.position = \"none\") +\n  scale_color_viridis_d() +\n  labs(title = \"Popularity ~ Extraversion\")\n\n\n\n\nThe goal here it estimate the average effect of extraversion on popularity. However, we assume that this effect will vary by class, and it might also depend on the pupils’ sex. Furthermore, classes may vary by how many years of experience a teacher has. We assume that this might be important.\nIntercept-only model\nStart by fitting an intercept-only model. With this we will predict\n\n\nShow code\n\nfit1 <- brm(popular ~ 1 + (1 | class),\n            data = popularity,\n            file = \"models/pop-fit1\")\n\n\n\nIn this model, we are estimating the average the average popularity over classes, as well as the deviation from this average for each class.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]}, \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\nFirst level predictors\nNow you can add some level 1 predictors, e.g. sex, extrav. You can use the update() so that you don’t have to rerun the compilation steps.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nfit1 |> \n  update(. ~ . + sex, \n         prior = prior(normal(0, 2), class = b),\n         newdata = popularity)\n\n\n\nThis is equivalent to\n\n\nShow code\n\nfit2 <- brm(popular ~ 1 + sex + extrav + (1|class),  \n              prior = prior(normal(0, 2), class = b),\n              data = popularity, \n            iter = 4000,\n            file = \"models/pop-fit2\") \n\n\n\nSecond level predictors\nNow add the the level-2 predictor teacher experience.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\gamma_{0}^{\\alpha} + \\gamma_{1}^{\\alpha}(\\operatorname{teacher\\_exp}), \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nfit3 <- fit2 |> update(. ~ . + teacher_exp,\n                       file = \"models/pop-fit3\",\n                       newdata = popularity)\n\n\n\nor equivalently\n\n\nShow code\n\nfit3 <- brm(popular ~ 1 + sex + extrav + teacher_exp + (1 | class),  \n            prior = prior(normal(0, 2), class = b),\n            data = popularity,\n            file = \"models/pop-fit3\") \n\n\n\nNow it’s time for some plots.\n\n\nShow code\n\nfit2 |> mcmc_plot()\n\n\n\n\n\n\nShow code\n\nfit3 |> mcmc_plot()\n\n\n\n\nModel comparisons\n\n\nShow code\n\nloo2 <- loo(fit2)\nloo3 <- loo(fit3)\n\n\n\n\n\nShow code\n\nloo_compare(loo2, loo3)\n\n\n     elpd_diff se_diff\nfit3  0.0       0.0   \nfit2 -1.6       2.5   \n\n\n\nShow code\n\nbayes_R2(fit2)\n\n\n    Estimate   Est.Error      Q2.5     Q97.5\nR2 0.6903738 0.006662371 0.6768908 0.7027676\n\nShow code\n\nbayes_R2(fit3)\n\n\n    Estimate  Est.Error      Q2.5     Q97.5\nR2 0.6905302 0.00680099 0.6767647 0.7035434\n\n\n\nShow code\n\nperformance::r2_bayes(fit2)\n\n\n# Bayesian R2 with Standard Error\n\n  Conditional R2: 0.691 (89% CI [0.680, 0.701])\n     Marginal R2: 0.388 (89% CI [0.372, 0.405])\n\nShow code\n\nperformance::r2_bayes(fit3)\n\n\n# Bayesian R2 with Standard Error\n\n  Conditional R2: 0.691 (89% CI [0.680, 0.701])\n     Marginal R2: 0.510 (89% CI [0.485, 0.536])\n\nCross-level interaction\nLet teacher experience interact with extraversion. This is what’s known as a cross-level interaction; extraversion is a predictor of the level 1 units (pupils), whereas teacher experience is s predictor at level 2 (classes). This can be verified by looking at the dataframe—teacher experience does not have one unique value per observation, but instead for each class.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2j[i]}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{2j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\gamma_{0}^{\\alpha} + \\gamma_{1}^{\\alpha}(\\operatorname{teacher\\_exp}) \\\\\n      &\\gamma^{\\beta_{2}}_{0} + \\gamma^{\\beta_{2}}_{1}(\\operatorname{teacher\\_exp})\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{2j}} \\\\ \n     \\rho_{\\beta_{2j}\\alpha_{j}} & \\sigma^2_{\\beta_{2j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nfit4 <- brm(popular ~ 1 + sex + extrav + teacher_exp + extrav:teacher_exp + \n                (1 | class), \n            prior = prior(normal(0, 2), class = b),\n            data  = popularity,\n            iter = 4000,\n            file_refit = \"on_change\",\n            fit = \"models/pop-fi4\")\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB \\\n  foo.c\nclang -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Users/andrew/Library/R/4.1/library/Rcpp/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/unsupported\"  -I\"/Users/andrew/Library/R/4.1/library/BH/include\" -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/src/\"  -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppParallel/include/\"  -I\"/Users/andrew/Library/R/4.1/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include   -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:88:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\n\nShow code\n\nconditional_effects(fit4, \"extrav:teacher_exp\")\n\n\n\n\n\nYou can attempt to decide which models fit better than others by using loo.\n\n\n\n\n“Multilevel Analysis: Techniques and Applications, Third Edition.” n.d. Routledge & CRC Press. Accessed May 29, 2021. https://www.routledge.com/Multilevel-Analysis-Techniques-and-Applications-Third-Edition/Hox-Moerbeek-Schoot/p/book/9781138121362.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:05:14+02:00"
    },
    {
      "path": "assignment-4.html",
      "title": "Assignment 4",
      "description": "Effect of tDCS stimulation on episodic memory\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nEffect of tDCS on memory\nLinear model\nNull model\nModel comparison using loo\nModel comparison via Bayes factor\nControl for age\n\n\n\n\nShow code\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nEffect of tDCS on memory\nYou are going to analyze data from a study in which 34 elderly subjects were given anodal (activating) tDCS over their left tempero-parietal junction (TPJ). Subjects were instructed to learn association between images and pseudo-words (data were inspired by Antonenko et al. (2019)).\nEpisodic memory is measured by percentage of correctly recalled word-image pairings. We also have response times for correct decisions.\nEach subject was tested 5 times in the TPJ stimulation condition, and a further 5 times in a sham stimulation condition.\nThe variables in the dataset are:\nsubject: subject ID\nstimulation: TPJ or sham (control)\nblock: block\nage: age\ncorrect: accuracy per block\nrt: mean RTs for correct responses\nYou are mainly interested in whether recall ability is better during the TPJ stimulation condition than during sham.\n\n\nShow code\n\nd <- read_csv(\"https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/tdcs-tpj.csv\")\n\n\n\n\n\nShow code\n\nglimpse(d)\n\n\nRows: 340\nColumns: 6\n$ subject     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ stimulation <chr> \"control\", \"control\", \"control\", \"control\", \"con…\n$ block       <dbl> 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, …\n$ age         <dbl> 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 67, 67, …\n$ correct     <dbl> 0.8, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.6, 0.6, 0.8…\n$ rt          <dbl> 1.650923, 1.537246, 1.235620, 1.671189, 1.408333…\n\n\n\nShow code\n\nd <- d %>% \n  mutate(across(c(subject, stimulation, block), ~as_factor(.))) %>% \n  drop_na()\n\n\n\n\nspecify a linear model\nspecify a null model\ncompare models using approximate leave-one-out cross-validation\nestimate a Bayes factor for the effect of TPJ stimulation\nusing the Savage-Dickey density ratio test\nusing the bridge sampling method\n\ncontrol for subjects’ age\n\nLinear model\n\n\nShow code\n\nfit1 <- brm(correct ~ stimulation + (stimulation| subject),\n            prior = prior(normal(0, 1), class = b),\n            data = d,\n            file = \"models/ass4-1\")\n\n\n\n\n\nShow code\n\nsummary(fit1)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: correct ~ stimulation + (stimulation | subject) \n   Data: d (Number of observations: 315) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 34) \n                              Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                     0.04      0.02     0.00     0.08\nsd(stimulationTPJ)                0.03      0.02     0.00     0.08\ncor(Intercept,stimulationTPJ)    -0.12      0.56    -0.96     0.93\n                              Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                 1.00     1063     1691\nsd(stimulationTPJ)            1.00     1773     1704\ncor(Intercept,stimulationTPJ) 1.00     2638     2093\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept          0.43      0.02     0.39     0.46 1.00     4370\nstimulationTPJ     0.10      0.02     0.05     0.14 1.00     5662\n               Tail_ESS\nIntercept          2819\nstimulationTPJ     2553\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.19      0.01     0.18     0.21 1.00     4488     2904\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nShow code\n\nmcmc_plot(fit1, \"b_\", type = \"areas\")\n\n\n\n\nNull model\n\n\nShow code\n\nfit2 <- brm(correct ~ 1 + (stimulation| subject),\n            data = d,\n            file = \"models/ass4-2\")\n\n\n\nModel comparison using loo\n\n\nShow code\n\nloo_fit_1 <- loo(fit1)\nloo_fit_1\n\n\n\nComputed from 4000 by 315 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo     62.3 11.3\np_loo        14.4  1.1\nlooic      -124.7 22.6\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n\n\nShow code\n\nloo_fit_2 <- loo(fit2)\nloo_fit_2\n\n\n\nComputed from 4000 by 315 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo     54.3 10.8\np_loo        17.0  1.3\nlooic      -108.5 21.7\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     313   99.4%   1428      \n (0.5, 0.7]   (ok)         2    0.6%   1509      \n   (0.7, 1]   (bad)        0    0.0%   <NA>      \n   (1, Inf)   (very bad)   0    0.0%   <NA>      \n\nAll Pareto k estimates are ok (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\n\nShow code\n\nloo_compare(loo_fit_1, loo_fit_2)\n\n\n     elpd_diff se_diff\nfit1  0.0       0.0   \nfit2 -8.1       3.7   \n\nModel comparison via Bayes factor\n\n\nShow code\n\nfit1_bf <- brm(correct ~ stimulation + (stimulation| subject),\n            prior = prior(normal(0, 1), class = b),\n            data = d,\n            iter = 1e4,\n            save_pars = save_pars(all = TRUE),\n            file = \"models/ass4-bf_1\")\n\n\n\n\n\nShow code\n\nfit2_bf <- brm(correct ~ 1 + (stimulation| subject),\n            prior = prior(normal(0, 1), class = b),\n            data = d,\n            iter = 1e4,\n            save_pars = save_pars(all = TRUE),\n            file = \"models/ass4-bf_2\")\n\n\n\n\n\nShow code\n\nloglik_1 <- bridge_sampler(fit1_bf, silent = TRUE)\nloglik_2 <- bridge_sampler(fit2_bf, silent = TRUE)\n\n\n\n\n\nShow code\n\nBF_10 <- bayes_factor(loglik_1, loglik_2)\nBF_10\n\n\nEstimated Bayes factor in favor of x1 over x2: 115.99740\n\nControl for age\n\n\nShow code\n\nfit3 <- brm(correct ~ stimulation + age + (stimulation | subject),\n            prior = prior(normal(0, 1), class = b),\n            data = d,\n            file = \"models/ass4-3\")\n\n\n\n\n\nShow code\n\nfit3\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: correct ~ stimulation + age + (stimulation | subject) \n   Data: d (Number of observations: 315) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 34) \n                              Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                     0.03      0.02     0.00     0.07\nsd(stimulationTPJ)                0.03      0.02     0.00     0.08\ncor(Intercept,stimulationTPJ)    -0.07      0.56    -0.95     0.92\n                              Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                 1.00     1066     1325\nsd(stimulationTPJ)            1.00     1476     2197\ncor(Intercept,stimulationTPJ) 1.00     2435     1959\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept          0.16      0.25    -0.33     0.64 1.00     4074\nstimulationTPJ     0.10      0.02     0.05     0.14 1.00     5234\nage                0.00      0.00    -0.00     0.01 1.00     4075\n               Tail_ESS\nIntercept          2701\nstimulationTPJ     2720\nage                2688\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.19      0.01     0.18     0.21 1.00     3919     2810\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nShow code\n\nloo_fit_3 <- loo(fit3)\n\n\n\n\n\nShow code\n\nloo_compare(loo_fit_1, loo_fit_3)\n\n\n     elpd_diff se_diff\nfit1  0.0       0.0   \nfit3 -0.4       1.0   \n\n\n\nShow code\n\nfit3_bf <- brm(correct ~ stimulation + age + (stimulation| subject),\n            prior = prior(normal(0, 1), class = b),\n            data = d,\n            iter = 1e4,\n            save_pars = save_pars(all = TRUE),\n            file = \"models/ass4-bf_3\")\n\n\n\n\n\nShow code\n\nloglik_3 <- bridge_sampler(fit3_bf, silent = TRUE)\n\n\n\n\n\nShow code\n\nBF_01 <- bayes_factor(loglik_3, loglik_1)\nBF_01\n\n\nEstimated Bayes factor in favor of x1 over x2: 0.00668\n\n\n\n\nAntonenko, Daria, Dayana Hayek, Justus Netzband, Ulrike Grittner, and Agnes Flöel. 2019. “tDCS-Induced Episodic Memory Enhancement and Its Association with Functional Network Coupling in Older Adults.” Scientific Reports 9 (1, 1): 2273. https://doi.org/10.1038/s41598-019-38630-7.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:05:31+02:00"
    },
    {
      "path": "binary-models.html",
      "title": "Models for Binary Data",
      "description": "Logistic regression / item response models\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "06-11-2021",
      "contents": "\n\nContents\nLogistic Regression\nLikelihood\nPrior distributions\nFitting models\n\nItem Response Models\nResponse distributions\nData\nPartial pooling for items\nNo pooling for items\nPerson and item parameters\n\n\n\n\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(brms)\n\n# set ggplot theme\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n# set rstan options\nrstan::rstan_options(auto_write = TRUE)\noptions(mc.cores = 4)\n\n\n\nLogistic Regression\nThis example is based onBayesian Data Analysis for Cognitive Science and uses data from (oberauerWorkingMemoryCapacity2019?).\nIn this study, the effect of word list length on working memory capacity was assessed. Subjects were shown word lists of varying length (set size: 2, 4, 6, or 8 words) and were required to recall the correct word according to its position in the list. A single trial is shown in Figure 1.\n\n\n\nFigure 1: Subjects were required to indicate the correct word from the studied list according to its cued position.\n\n\n\n\n\nrecall <- read_csv(file = \"data/recall-oberauer.csv\")\n\nrecall <- recall |> \n  mutate(subj = as_factor(subj))\n\n\n\n\n\nglimpse(recall)\n\n\nRows: 12,880\nColumns: 9\n$ subj              <fct> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10…\n$ session           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ block             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ trial             <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…\n$ set_size          <dbl> 4, 4, 2, 8, 6, 2, 8, 6, 2, 6, 4, 8, 8, 8, …\n$ response          <dbl> 430, 925, 533, 45, 477, 1105, 828, 193, 31…\n$ rt                <dbl> -1.000, 1.586, 1.399, -1.000, 2.301, 2.424…\n$ correct           <dbl> 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, …\n$ response_category <chr> \"correct\", \"correct\", \"correct\", \"new\", \"c…\n\nCount the number of subjects and number of trials per set size for each subjetc.\n\n\nrecall |> distinct(subj) |> count()\n\n\n# A tibble: 1 x 1\n      n\n  <int>\n1    20\n\nrecall |> count(subj, set_size)\n\n\n# A tibble: 80 x 3\n   subj  set_size     n\n   <fct>    <dbl> <int>\n 1 1            2    92\n 2 1            4   138\n 3 1            6   184\n 4 1            8   230\n 5 2            2    92\n 6 2            4   138\n 7 2            6   184\n 8 2            8   230\n 9 3            2    92\n10 3            4   138\n# … with 70 more rows\n\nThe latter is equivalent to:\n\n\nrecall |> group_by(subj, set_size) |>\n  summarize(N = n())\n\n\n# A tibble: 80 x 3\n# Groups:   subj [20]\n   subj  set_size     N\n   <fct>    <dbl> <int>\n 1 1            2    92\n 2 1            4   138\n 3 1            6   184\n 4 1            8   230\n 5 2            2    92\n 6 2            4   138\n 7 2            6   184\n 8 2            8   230\n 9 3            2    92\n10 3            4   138\n# … with 70 more rows\n\nBefore fitting any models, we will center the set_size variable.\n\n\nrecall <- recall |> \n  mutate(c_set_size = set_size - mean(set_size))\n\n\n\nWe are interested in subjects’ probability of responding correctly based on the set size. First, we can get a maximum likelihood estimate:\n\n\nrecall_sum <- recall %>% \n  group_by(subj, set_size) %>% \n  summarise(accuracy = mean(correct),\n            sd = sd(correct))\n\n\n\n\n\nrecall_sum |> \n  ggplot(aes(set_size, accuracy)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~subj)\n\n\n\n\nLikelihood\nInstead of computing point estimates, we can model these data using a generalized linear model. We know that each response is either correct or an error, and thus the most sensible distribution is a Bernoulli.\n\\[ correct_i \\sim Bernoulli(\\theta_{i})\\]\nEach response \\(i\\) is drawn from a Bernoulli distribution, with a probability of being correct of \\(\\theta_i\\). THe probability of an error response is \\(1-\\theta_i\\).\nWe want to predict the probability of getting a correct response using a linear predictor. Since the linear predictor in on the real line, and the parameter we are trying to predict lies in the interval \\([0, 1]\\), we need to transform the linear predictor. This is conventionally written as\n\\[ g(\\theta_i) = logit(\\theta_i) = b_0 + b_{set\\_size} \\cdot set\\_size_i \\] with the link function \\(g()\\) being applied to the parameter of the likelihood distribution. An alternative way of writing this is\n\\[ \\theta_i = g^{-1}(b_0 + b_{set\\_size} \\cdot set\\_size_i) \\]\nwhere \\(g^{-1}\\) is the inverse link function.\nIn a logistic regression, the link function is the logit function:\n\\[ logit(\\theta) = log \\bigg( \\frac{\\theta}{(1-\\theta)} \\bigg) \\] and gives the log-odds, i.e. the natural logarithm of the odds of a success.\nTherefore(for a single subject)\n\\[ log \\bigg( \\frac{\\theta_i}{1-\\theta_i} \\bigg) = b_0 + b_{set\\_size} \\cdot set\\_size_i \\] The coefficients \\(b_0\\) and \\(b_{set\\_size}\\) have an additive effect on the log-odds scale. If we want this effect on the probability scale, we need to apply the inverse link function. This is is function \\(f(x) = 1/(1 + exp(-x))\\), and is known a the logistic function. It is also the cumulative distribution function of the logistic distribution, and exist in R under the name plogis().\nFor example, if the log-odds are 0.1, then the probability is 0.525:\n\n\nlogodds <- 0.1\nprob <- plogis(logodds)\nprob\n\n\n[1] 0.5249792\n\nWe can plot the log-odds on the x axis, and the cumulative distribution on the y axis. Is it noticeable that the log-odds with an absolute value greater than approximately 5 lead to probabilities of 0 and 1, asymptotically. This is relevant when considering prior distributions.\n\n\nd1 <- tibble(x = seq(-5, 5, by = 0.01),\n            y = plogis(x))\n\nd1 %>% \n    ggplot(aes(x, y)) +\n    geom_hline(yintercept = 0.5, linetype = 3) +\n    geom_vline(xintercept = 0, linetype = 3) +\n    geom_line(size = 2, color = \"steelblue\") +\n    xlab(\"log-odds\") + ylab(\"probability of success\")\n\n\n\n\nPrior distributions\nSince we centered our predictor variable c_set_size, the zero point represents the average set size. The intercept will therefore represent the expected log-odds for the average set size. With minimal prior knowledge, we may assume that at the average set size, a subject may be equally likely to give a correct or error response. In that case, \\(\\theta = 0.5\\), and the log-odds are \\(0\\).\nWe can express our uncertainty using a normal distribution centred at 0, with a standard deviation of 1, i.e. we are 95% certain that the log-odds will lie between \\([-2, 2]\\).\n\n\nqnorm(c(.025, .975), mean = 0, sd = 1.0)\n\n\n[1] -1.959964  1.959964\n\nYOu can plot the prior by using random draws from a normal distribution. The figure on the left shows the normal distribution on the log-odds scale, and the figure on the right shows the transformed values, on the probability scale.\n\n\nlibrary(patchwork)\n\nsamples <- tibble(Intercept = rnorm(1e5, 0, 1.0),\n                  p = plogis(Intercept))\n\np_logodds <- samples %>% \n  ggplot(aes(Intercept)) +\n  geom_density() +\n  ggtitle(\"Log-odds\")\n\np_prob <- samples %>% \n  ggplot(aes(p)) +\n  geom_density() +\n  ggtitle(\"Probability\")\n\n\np_logodds + p_prob\n\n\n\n\nOur normal(0, 1.0) prior is very similar to using a Beta(2, 2) on the probability scale..\n\n\ntibble(x = seq(0, 1, by = 0.01),\n       dens =  dbeta(x, shape1 = 2, shape2 = 2)) %>% \n  ggplot(aes(x, dens)) +\n  geom_line()\n\n\n\n\nFor the average effect of set_size we will choose a prior on the log-odds scale that is uninformative on the probability scale. A normal(0, 0.5) prior expresses the belief that the an increase of the set size by one unit will lead to an change in the log-odds of somewhere between \\([-1, 1]\\), with a probability of 95%. The figure on the right again shows the effect transformed onto the probability scale.\n\n\nsamples2 <- tibble(b_set_size = rnorm(1e5, 0, 0.5),\n                          p = plogis(b_set_size))\n\np_logodds <- samples2 %>% \n  ggplot(aes(b_set_size)) +\n  geom_density() +\n  ggtitle(\"Log-odds\")\n\np_prob <- samples2 %>% \n  ggplot(aes(p)) +\n  geom_density() +\n  ggtitle(\"Probability\")\n\n\np_logodds + p_prob\n\n\n\n\nFitting models\nWe have set our priors on the average (population-level) effects of the set size. Let’s look at the default priors in a multilevel model\n\n\nlibrary(brms)\n\n\n\n\n\nget_prior(correct ~ 1 + c_set_size + (1 + c_set_size | subj),\n                family = bernoulli(link = logit),\n                data = recall)\n\n\n                prior     class       coef group resp dpar nlpar\n               (flat)         b                                 \n               (flat)         b c_set_size                      \n               lkj(1)       cor                                 \n               lkj(1)       cor             subj                \n student_t(3, 0, 2.5) Intercept                                 \n student_t(3, 0, 2.5)        sd                                 \n student_t(3, 0, 2.5)        sd             subj                \n student_t(3, 0, 2.5)        sd c_set_size  subj                \n student_t(3, 0, 2.5)        sd  Intercept  subj                \n bound       source\n            default\n       (vectorized)\n            default\n       (vectorized)\n            default\n            default\n       (vectorized)\n       (vectorized)\n       (vectorized)\n\n\n\npriors <- prior(normal(0, 1.0), class = Intercept) +\n    prior(normal(0, .1), class = b, coef = c_set_size)\n\nfit_recall_1 <- brm(correct ~ 1 + c_set_size + (1 + c_set_size | subj),\n                family = bernoulli(link = logit),\n                prior = priors,\n                data = recall,\n                file = \"models/fit_recall-1\",\n                file_refit = \"on_change\")\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB \\\n  foo.c\nclang -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Users/andrew/Library/R/4.1/library/Rcpp/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/unsupported\"  -I\"/Users/andrew/Library/R/4.1/library/BH/include\" -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/src/\"  -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppParallel/include/\"  -I\"/Users/andrew/Library/R/4.1/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include   -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:88:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\n\nfit_recall_1\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: correct ~ 1 + c_set_size + (1 + c_set_size | subj) \n   Data: recall (Number of observations: 12880) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~subj (Number of levels: 20) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)                 0.56      0.13     0.37     0.83 1.00\nsd(c_set_size)                0.09      0.04     0.02     0.18 1.00\ncor(Intercept,c_set_size)    -0.56      0.28    -0.95     0.14 1.00\n                          Bulk_ESS Tail_ESS\nsd(Intercept)                  892     1257\nsd(c_set_size)                 833     1097\ncor(Intercept,c_set_size)     1376     1448\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept      2.23      0.15     1.91     2.51 1.01      589\nc_set_size    -0.53      0.03    -0.58    -0.45 1.01     1004\n           Tail_ESS\nIntercept       769\nc_set_size      847\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nfit_recall_1 |> mcmc_plot()\n\n\n\n\nWe can plot the expected effect of set size on the probability of giving a correct response using `conditional_effects. The default shows the exptected value of the posterior predictive distribution.\n\n\nfit_recall_1 |> \n  conditional_effects()\n\n\n\n\nIf you want the expected log-odds, you can use the argument method = 'posterior_linpred'.\n\n\nfit_recall_1 |> \n  conditional_effects(method = 'posterior_linpred')\n\n\n\n\nItem Response Models\nWe will look at an example from Bürkner (2020). I would thoroughly recommend reading this if you are interested in logistics regression models, and Item Response Theory (IRT) models in particular.\nIRT models are widely applied in the human sciences to model persons’ responses on a set of items measuring one or more latent constructs.\nResponse distributions\nThe response format of the items will critically determine which distribution is appropriate to model individuals’ responses on the items. The possibility of using a wide range of response distributions within the same framework and estimating all of them using the same general-purpose algorithms is an important advantage of Bayesian statistics.\nIf the response \\(y\\) is a binary success (1) vs. failure (0) indicator, the canonical family is the Bernoulli distribution with density\n\\[\ny \\sim \\text{Bernoulli}(\\psi) = \\psi^y (1-\\psi)^{1-y},\n\\] where \\(\\psi \\in [0, 1]\\) can be interpreted as the success probability. Common IRT models that can be built on top of the Bernoulli distribution are the 1, 2, and 3 parameter logistic models (1PL, 2PL, and 3PL models).\nThis results in what is known as a generalized linear model (GLM). That is, the predictor term \\(\\eta = \\theta_p + \\xi_i\\) is still linear but transformed, as a whole, by a non-linear function \\(f\\), which is commonly called ‘response function.’ For Bernoulli distributions, we can canonically use the logistic response function\n\\[\nf(\\eta) = \\text{logistic}(\\eta) = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)},\n\\]\nwhich yields values \\(f(\\eta) \\in [0, 1]\\) for any real value \\(\\eta\\). As a result, we could write down the model of \\(\\psi\\) as\n\\[\n\\psi = \\frac{\\exp(\\theta_p + \\xi_i)}{1 + \\exp(\\theta_p + \\xi_i)},\n\\]\nwhich is known as the Rasch or 1PL model. Under the above model, we can interprete \\(\\theta_p\\) as the ability of person \\(p\\) (higher values of \\(\\theta_p\\) imply higher success probabilities regardless of the administered item). \\(\\xi_i\\) can be interpreted as the easiness of item \\(i\\) (higher values of \\(\\xi_i\\) imply higher success probabilities regardless of the person to which the item is administered).\nData\nThe dataset is taken from De Boeck et al. (2011) and is included in the lme4 package.\nThere are 24 items, based on four frustrating situations, two of which where someone else is to be blamed (e.g., “A bus fails to stop for me”), and two of which where one is to be blamed oneself (e.g., “I am entering a grocery store when it is about to close”). Each of these situations is combined with each of three behaviors, cursing, scolding, and shouting, leading to 4x3 combinations. These 12 combinations are formulated in two modes, a wanting mode and a doing mode, so that in total there are 24 items. An example is “A bus fails tostop for me. I would want to curse.”\n\n\ndata(\"VerbAgg\", package = \"lme4\") \nVerbAgg <- VerbAgg |> as_tibble()\n\nhead(VerbAgg, 10)\n\n\n# A tibble: 10 x 9\n   Anger Gender item        resp    id    btype situ  mode  r2   \n   <int> <fct>  <fct>       <ord>   <fct> <fct> <fct> <fct> <fct>\n 1    20 M      S1WantCurse no      1     curse other want  N    \n 2    11 M      S1WantCurse no      2     curse other want  N    \n 3    17 F      S1WantCurse perhaps 3     curse other want  Y    \n 4    21 F      S1WantCurse perhaps 4     curse other want  Y    \n 5    17 F      S1WantCurse perhaps 5     curse other want  Y    \n 6    21 F      S1WantCurse yes     6     curse other want  Y    \n 7    39 F      S1WantCurse yes     7     curse other want  Y    \n 8    21 F      S1WantCurse no      8     curse other want  N    \n 9    24 F      S1WantCurse no      9     curse other want  N    \n10    16 F      S1WantCurse yes     10    curse other want  Y    \n\nThe variables are:\n\n\nVariable\n\n\nDescription\n\n\nAnger\n\n\nthe subject’s Trait Anger score as measured on the State-Trait Anger Expression Inventory (STAXI)\n\n\nGender\n\n\nthe subject’s gender - a factor with levels M and F\n\n\nitem\n\n\nthe item on the questionaire, as a factor\n\n\nresp\n\n\nthe subject’s response to the item - an ordered factor with levels no < perhaps < yes\n\n\nid\n\n\nthe subject identifier, as a factor\n\n\nbtype\n\n\nbehavior type - a factor with levels curse, scold and shout\n\n\nsitu\n\n\nsituation type - a factor with levels other and self indicating other-to-blame and self-to-blame\n\n\nmode\n\n\nbehavior mode - a factor with levels want and do\n\n\nr2\n\n\ndichotomous version of the response - a factor with levels N and Y\n\n\nPartial pooling for items\n\n\nformula_1pl <- bf(r2 ~ 1 + (1 | item) + (1 | id))\n\n\n\n\n\nget_prior(formula_1pl,\n                  data = VerbAgg, \n                  family = bernoulli())\n\n\n                prior     class      coef group resp dpar nlpar bound\n student_t(3, 0, 2.5) Intercept                                      \n student_t(3, 0, 2.5)        sd                                      \n student_t(3, 0, 2.5)        sd              id                      \n student_t(3, 0, 2.5)        sd Intercept    id                      \n student_t(3, 0, 2.5)        sd            item                      \n student_t(3, 0, 2.5)        sd Intercept  item                      \n       source\n      default\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n\nTo impose a small amount of regularization on the model, we’ll set \\(\\text{half-normal}(0, 3)\\) priors on the hierarchical standard deviations of person and items parameters. Given the scale of the logistic response function, this can be regarded as a weakly informative prior.\n\n\nprior_1pl <- \n  prior(\"normal(0, 3)\", class = \"sd\", group = \"id\") + \n  prior(\"normal(0, 3)\", class = \"sd\", group = \"item\")\n\n\n\n\n\nfit_1pl <- brm(formula_1pl,\n                  prior = prior_1pl,\n                  data = VerbAgg, \n                  family = bernoulli(),\n                  file = \"models/fit_va_1pl\") |> \n  add_criterion(\"loo\")\n\n\n\n\n\nsummary(fit_1pl)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ 1 + (1 | item) + (1 | id) \n   Data: VerbAgg (Number of observations: 7584) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 316) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)     1.39      0.07     1.26     1.53 1.00     1054\n              Tail_ESS\nsd(Intercept)     2168\n\n~item (Number of levels: 24) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)     1.23      0.20     0.91     1.69 1.00      573\n              Tail_ESS\nsd(Intercept)      978\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.17      0.26    -0.68     0.34 1.01      340      676\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit_1pl, ask = FALSE)\n\n\n\n\nNo pooling for items\n\n\nfit_1pl_nopooling <- brm(r2 ~ 0 + item + (1 | id),\n                  prior =  prior(\"normal(0, 3)\", class = \"sd\", group = \"id\"),\n                  data = VerbAgg, \n                  family = bernoulli(),\n                  file = \"models/fit_1pl_nopooling\") |> \n  add_criterion(\"loo\")\n\n\n\n\n\nsummary(fit_1pl_nopooling)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ 0 + item + (1 | id) \n   Data: VerbAgg (Number of observations: 7584) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 316) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)     1.40      0.07     1.27     1.54 1.00     1335\n              Tail_ESS\nsd(Intercept)     2612\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nitemS1WantCurse     1.23      0.16     0.91     1.55 1.00     1500\nitemS1WantScold     0.57      0.15     0.27     0.87 1.00     1435\nitemS1WantShout     0.08      0.15    -0.21     0.38 1.00     1359\nitemS2WantCurse     1.76      0.18     1.42     2.10 1.00     1673\nitemS2WantScold     0.71      0.16     0.40     1.03 1.00     1563\nitemS2WantShout     0.02      0.15    -0.28     0.32 1.00     1593\nitemS3WantCurse     0.54      0.16     0.23     0.84 1.00     1228\nitemS3WantScold    -0.68      0.16    -1.00    -0.38 1.00     1519\nitemS3WantShout    -1.53      0.17    -1.87    -1.21 1.00     1744\nitemS4wantCurse     1.09      0.16     0.77     1.41 1.00     1807\nitemS4WantScold    -0.35      0.16    -0.66    -0.05 1.00     1567\nitemS4WantShout    -1.04      0.16    -1.36    -0.74 1.00     1561\nitemS1DoCurse       1.23      0.17     0.89     1.55 1.00     1720\nitemS1DoScold       0.39      0.16     0.10     0.71 1.00     1346\nitemS1DoShout      -0.87      0.16    -1.19    -0.56 1.00     1638\nitemS2DoCurse       0.88      0.16     0.57     1.18 1.00     1594\nitemS2DoScold      -0.05      0.16    -0.35     0.25 1.00     1360\nitemS2DoShout      -1.49      0.17    -1.82    -1.16 1.00     1224\nitemS3DoCurse      -0.21      0.15    -0.51     0.09 1.00      983\nitemS3DoScold      -1.51      0.17    -1.85    -1.16 1.00     1593\nitemS3DoShout      -2.99      0.23    -3.47    -2.53 1.00     3110\nitemS4DoCurse       0.72      0.15     0.42     1.01 1.00     1354\nitemS4DoScold      -0.38      0.16    -0.69    -0.09 1.00     1525\nitemS4DoShout      -2.01      0.18    -2.38    -1.65 1.00     1928\n                Tail_ESS\nitemS1WantCurse     2468\nitemS1WantScold     2701\nitemS1WantShout     2014\nitemS2WantCurse     2321\nitemS2WantScold     1981\nitemS2WantShout     2841\nitemS3WantCurse     2120\nitemS3WantScold     2386\nitemS3WantShout     2394\nitemS4wantCurse     2097\nitemS4WantScold     2301\nitemS4WantShout     2506\nitemS1DoCurse       1951\nitemS1DoScold       2372\nitemS1DoShout       2409\nitemS2DoCurse       2580\nitemS2DoScold       2071\nitemS2DoShout       2334\nitemS3DoCurse       2023\nitemS3DoScold       2294\nitemS3DoShout       2550\nitemS4DoCurse       2515\nitemS4DoScold       2354\nitemS4DoShout       2553\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nPerson and item parameters\n\n\n# extract person parameters\nranef_1pl <- ranef(fit_1pl)\nperson_pars_1pl <- ranef_1pl$id\n\nhead(person_pars_1pl, 10)\n\n\n, , Intercept\n\n      Estimate Est.Error       Q2.5      Q97.5\n1  -0.47616473 0.4632101 -1.3984419  0.4111084\n2  -2.63150728 0.6678232 -4.0876808 -1.4323015\n3  -0.28425523 0.4467831 -1.1663240  0.5810175\n4   0.50622654 0.4470079 -0.3608196  1.4072071\n5  -0.27544278 0.4528381 -1.1519362  0.5944849\n6  -0.07585822 0.4361786 -0.9397340  0.8037192\n7   0.49986026 0.4613523 -0.4069441  1.3985131\n8  -1.60714598 0.5332954 -2.7036625 -0.6015083\n9  -0.28863647 0.4533358 -1.1759914  0.5773946\n10  1.88803225 0.5623813  0.8718271  3.0627982\n\n\n\n# extract item parameters\nitem_pars_1pl <- coef(fit_1pl)$item\nhead(item_pars_1pl, 10)\n\n\n, , Intercept\n\n               Estimate Est.Error       Q2.5      Q97.5\nS1WantCurse  1.20196140 0.1601299  0.8901030  1.5052450\nS1WantScold  0.55653464 0.1507762  0.2637651  0.8504478\nS1WantShout  0.07696848 0.1519015 -0.2219838  0.3738717\nS2WantCurse  1.71960862 0.1771338  1.3739380  2.0824048\nS2WantScold  0.69594168 0.1544957  0.3894525  1.0009871\nS2WantShout  0.01174867 0.1539789 -0.2869682  0.3169380\nS3WantCurse  0.52177493 0.1562612  0.2082198  0.8251145\nS3WantScold -0.67988768 0.1532981 -0.9780379 -0.3789035\nS3WantShout -1.50433502 0.1701056 -1.8390317 -1.1747919\nS4wantCurse  1.06641747 0.1649784  0.7499007  1.3929517\n\n\n\n# plot item parameters\nitem_pars_1pl[, , \"Intercept\"] %>%\n  as_tibble() %>%\n  rownames_to_column() %>%\n  rename(item = \"rowname\") %>%\n  mutate(item = as.numeric(item)) %>%\n  ggplot(aes(item, Estimate, ymin = Q2.5, ymax = Q97.5)) +\n  geom_pointrange() +\n  coord_flip() +\n  labs(x = \"Item Number\")\n\n\n\n\n\n\n# plot person parameters\nperson_pars_1pl[, , \"Intercept\"] %>%\n  as_tibble() %>%\n  rownames_to_column() %>%\n  arrange(Estimate) %>%\n  mutate(id = seq_len(n())) %>%\n  ggplot(aes(id, Estimate, ymin = Q2.5, ymax = Q97.5)) +\n  geom_pointrange(alpha = 0.4) +\n  coord_flip() +\n  labs(x = \"Person Number (Sorted)\")\n\n\n\n\n\n\nlibrary(tidybayes)\n\nfit_1pl |> \n  spread_draws(r_id[id,Intercept])\n\n\n# A tibble: 1,264,000 x 6\n# Groups:   id, Intercept [316]\n      id Intercept   r_id .chain .iteration .draw\n   <int> <chr>      <dbl>  <int>      <int> <int>\n 1     1 Intercept -0.720      1          1     1\n 2     1 Intercept -0.368      1          2     2\n 3     1 Intercept -0.772      1          3     3\n 4     1 Intercept -0.757      1          4     4\n 5     1 Intercept -0.487      1          5     5\n 6     1 Intercept -0.632      1          6     6\n 7     1 Intercept -0.624      1          7     7\n 8     1 Intercept -0.672      1          8     8\n 9     1 Intercept -0.576      1          9     9\n10     1 Intercept -0.561      1         10    10\n# … with 1,263,990 more rows\n\n\n\nvarying_item_effects <- fit_1pl |> \n  spread_draws(b_Intercept, r_item[item, Intercept]) |> \n  median_qi(difficulty = b_Intercept + r_item, .width = c(.95)) |> \n  arrange(difficulty) \n\nvarying_item_effects |> \n  ggplot(aes(y = item, x = difficulty, xmin = .lower, xmax = .upper)) +\n  geom_pointinterval(alpha = 0.4) +\n  ggtitle(\"Partial pooling estimates\")\n\n\n\n\n\n\npopulation_item_effects <- fit_1pl_nopooling |> \n  gather_draws(`b_item.*`, regex = TRUE) |> \n  median_qi(.width = c(.95))\n\n\n\n\n\npopulation_item_effects |> \n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) +\n  geom_pointinterval(alpha = 0.4) +\n  ggtitle(\"No pooling estimates\")\n\n\n\n\n\n\n\nBürkner, Paul-Christian. 2020. “Bayesian Item Response Modeling in R with Brms and Stan.” February 1, 2020. http://arxiv.org/abs/1905.09501.\n\n\nDe Boeck, Paul, Marjan Bakker, Robert Zwitser, Michel Nivard, Abe Hofman, Francis Tuerlinckx, and Ivailo Partchev. 2011. “The Estimation of Item Response Models with the Lmer Function from the Lme4 Package in R.” Journal of Statistical Software 39 (12): 1–28. https://doi.org/10.18637/jss.v039.i12.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:05:36+02:00"
    },
    {
      "path": "index.html",
      "title": "Learn multilevel models workshop",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-06-11T06:05:36+02:00"
    },
    {
      "path": "intro.html",
      "title": "Introduction",
      "description": "Bayesian multilevel modelling workshop 2021\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-21-2021",
      "contents": "\n\nContents\nWhat is this workshop about?\nOutline\nFriday, May 21\nFriday, May 28\nSaturday, May 29\nFriday, June 4\n\nPrerequisites\nSoftware\nAssignments\nZulip\n\nWhat is this workshop about?\nThis workshop will focus on hierarchical (multilevel) regression models from various angles. While reading your expectations and questions regarding this workshop, it became clear that all of your points can be approached within the same framework, i.e. Bayesian hierarchical generalized regression models. We will spend a lot of time learning to understand and specify these types of models. However, we will focus mainly on learning how to implement and work with these models, rather than spending time looking at the formal math. Here, I will follow the approach taken by McElreath (2020), who emphasises that even mathematicians may have trouble understanding something until they see a working algorithm.\nTherefore, this workshop will be very hands-on. Everything we do will be illustrated with working code examples, and you are encouraged to try every single line of code for yourself.\nOutline\nFriday, May 21\nWe will start with a general introduction to Bayesian inference, followed by an intro to the programming language Stan, and the R packages rstan and brms. Since we will be working almost exclusively with brms therafter, it is important to spend a bit of time here.\nWe will dive straight into Bayesian inference here, without spending too much time on frequentist methods and the differences between the two approaches (we will focus on this mode when we get to model comparisons).\nWe will then explore how models can be implemented as general (or generalized) linear models, and we will introduce multilevel models as a natural way of modelling reapeated measurements.\nFriday, May 28\nSaturday, May 29\nFriday, June 4\nPrerequisites\nBasic knowledge of regression models and R is a necessity. I strongly recommend that you prepare for the workshop by working through this online script: https://methodenlehre.github.io/intro-to-rstats. Previous exposure to multilevel models and longitudinal models would be helpful, but is not strictly necessary. Knowledge of Bayesian statistics is not required.\nSoftware\nWe will be using R and RStudio, as well a variety of R packages. It is advisable to ensure that you have a working R installation before the workshop starts, and that you install the two R packages rstan and brms. Detailed instructions for installing these packages on all platforms can be found at https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started and https://paul-buerkner.github.io/brms.\nAssignments\nWe will focus on learning new topics during the morning sessions, and participants should work through the assignments during the afternoon sessions. Participants are also encouraged to bring their own datasets.\nZulip\nThe Zulip chat server will be our communicatin platform for this workshop. We will use this for questions, assignments, troubleshooting, etc. Zulip can be used for synchronous or asynchronous chats, and has very good threading capabilities. Zulip is also pretty easy to use, and uses Markdown for message formatting. This means that you can use Markdown to format code and equations.\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd Edition. 2nd ed. CRC Press. http://xcelab.net/rm/statistical-rethinking/.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:05:37+02:00"
    },
    {
      "path": "longitudinal-models.html",
      "title": "Longitudinal Models",
      "description": "Modelling change over time\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "06-11-2021",
      "contents": "\n\nContents\nExlporing data\nEarly Intervention\nFitting the model with brms\n\nChanges in adolescent alcohol use\nUnconditional means model\nUnconditional growth model\nEffect of COA\n\nTime-varying predictors\nDecomposing time-varying predictors\n\n\nThe examples in this document are taken from Singer and Willett (n.d.) and the translation into tidyverse and brms code by Kurz (2021).\nWe will first briefly look at how to reshape datasets, and then investigate two examples of longitudinal data with a hierarchical structure.\n\n\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(brms)\n\n# set ggplot theme\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n# set rstan options\nrstan::rstan_options(auto_write = TRUE)\noptions(mc.cores = 4)\n\n\n\nExlporing data\nWe’ll load a dataset from RAUDENBUSH and CHAN (1992).\n\n\ntolerance <- read_csv(\"https://stats.idre.ucla.edu/wp-content/uploads/2016/02/tolerance1.txt\", col_names = TRUE)\n\nhead(tolerance, n = 16)\n\n\n# A tibble: 16 x 8\n      id tol11 tol12 tol13 tol14 tol15  male exposure\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\n 1     9  2.23  1.79  1.9   2.12  2.66     0     1.54\n 2    45  1.12  1.45  1.45  1.45  1.99     1     1.16\n 3   268  1.45  1.34  1.99  1.79  1.34     1     0.9 \n 4   314  1.22  1.22  1.55  1.12  1.12     0     0.81\n 5   442  1.45  1.99  1.45  1.67  1.9      0     1.13\n 6   514  1.34  1.67  2.23  2.12  2.44     1     0.9 \n 7   569  1.79  1.9   1.9   1.99  1.99     0     1.99\n 8   624  1.12  1.12  1.22  1.12  1.22     1     0.98\n 9   723  1.22  1.34  1.12  1     1.12     0     0.81\n10   918  1     1     1.22  1.99  1.22     0     1.21\n11   949  1.99  1.55  1.12  1.45  1.55     1     0.93\n12   978  1.22  1.34  2.12  3.46  3.32     1     1.59\n13  1105  1.34  1.9   1.99  1.9   2.12     1     1.38\n14  1542  1.22  1.22  1.99  1.79  2.12     0     1.44\n15  1552  1     1.12  2.23  1.55  1.55     0     1.04\n16  1653  1.11  1.11  1.34  1.55  2.12     0     1.25\n\nThe data are in the wide format (one row per id), but we need one row per observation, so we need to rehape the data into a long format.\n\n\ntolerance <- tolerance |> \n  pivot_longer(-c(id, male, exposure),\n               names_to = \"age\", \n               values_to = \"tolerance\") |> \n  # remove the `tol` prefix from the `age` values \n  mutate(age = str_remove(age, \"tol\") |> as.integer()) |> \n  arrange(id, age) \n\n\n\nWe have 16 subjects.\n\n\ntolerance %>% \n  distinct(id) %>% \n  count()\n\n\n# A tibble: 1 x 1\n      n\n  <int>\n1    16\n\n\n\ntolerance %>%\n  slice(c(1:9, 76:80))\n\n\n# A tibble: 14 x 5\n      id  male exposure   age tolerance\n   <dbl> <dbl>    <dbl> <int>     <dbl>\n 1     9     0     1.54    11      2.23\n 2     9     0     1.54    12      1.79\n 3     9     0     1.54    13      1.9 \n 4     9     0     1.54    14      2.12\n 5     9     0     1.54    15      2.66\n 6    45     1     1.16    11      1.12\n 7    45     1     1.16    12      1.45\n 8    45     1     1.16    13      1.45\n 9    45     1     1.16    14      1.45\n10  1653     0     1.25    11      1.11\n11  1653     0     1.25    12      1.11\n12  1653     0     1.25    13      1.34\n13  1653     0     1.25    14      1.55\n14  1653     0     1.25    15      2.12\n\nFirst, we will plot the observations over time (at different ages), and connect them with lines.\n\n\ntolerance %>%\n  ggplot(aes(x = age, y = tolerance)) +\n  geom_point() +\n  geom_line() +\n  coord_cartesian(ylim = c(1, 4)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~id)\n\n\n\n\nNext, we will apply locally weighted smoothing.\n\n\ntolerance %>%\n  ggplot(aes(x = age, y = tolerance)) +\n  geom_point() +\n  stat_smooth(method = \"loess\", se = F, span = .9) +\n  coord_cartesian(ylim = c(1, 4)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~id)\n\n\n\n\nAnd finally, we’ll estimate the linear effect of age.\n\n\ntolerance %>%\n  ggplot(aes(x = age, y = tolerance)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F, span = .9) +\n  coord_cartesian(ylim = c(1, 4)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~id)\n\n\n\n\nEarly Intervention\nWe’ll start with a data set on early intervention on child development (Singer and Willett n.d.)\n\nAs part of a larger study of the effects of early intervention on child development, these researchers tracked the cognitive performance of 103 African- American infants born into low-income families. When the children were 6 months old, approximately half (n = 58) were randomly assigned to participate in an intensive early intervention program designed to enhance their cognitive functioning; the other half (n = 45) received no intervention and constituted a control group. Each child was assessed 12 times between ages 6 and 96 months. Here, we examine the effects of program participation on changes in cognitive performance as measured by a nationally normed test administered three times, at ages 12, 18, and 24 months.\n\n\nEach child has three records, one per wave of data collection. Each record contains four variables: (1) ID; (2) AGE, the child’s age (in years) at each assessment (1.0, 1.5, or 2.0); (3) COG, the child’s cognitive performance score at that age; and (4) PROGRAM, a dichotomy that describes whether the child participated in the early intervention program. Because children remained in their group for the duration of data collection, this predictor is time-invariant.\n\n\n\nearly_int <- read_csv(\"data/early-intervention.csv\") |> \n  mutate(id = as_factor(id),\n         intervention = factor(ifelse(program == 0, \"no\", \"yes\"),\n                               levels = c(\"no\", \"yes\")))\n\nhead(early_int, 10)\n\n\n# A tibble: 10 x 6\n   id      age   cog program age_c intervention\n   <fct> <dbl> <dbl>   <dbl> <dbl> <fct>       \n 1 1       1     117       1   0   yes         \n 2 1       1.5   113       1   0.5 yes         \n 3 1       2     109       1   1   yes         \n 4 2       1     108       1   0   yes         \n 5 2       1.5   112       1   0.5 yes         \n 6 2       2     102       1   1   yes         \n 7 3       1     112       1   0   yes         \n 8 3       1.5   113       1   0.5 yes         \n 9 3       2      85       1   1   yes         \n10 4       1     138       1   0   yes         \n\nIn addition, we have the age-1 variable, age_c. This variable has the value 0 when the child is 1 year old.\n\n\nearly_int |> \n  filter(id %in% sample(levels(early_int$id), 12)) |> \n  ggplot(aes(x = age, y = cog)) +\n  stat_smooth(method = \"lm\", se = F) +\n  geom_point() +\n  scale_x_continuous(breaks = c(1, 1.5, 2)) +\n  ylim(50, 150) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~id, ncol = 4)\n\n\n\n\nOur model for each child’s development is:\n\\[\n\\text{cog}_{ij} = [ \\pi_{0i} + \\pi_{1i} (\\text{age}_{ij} - 1) ] + [\\epsilon_{ij}].\n\\]\n\\[\\begin{align*}\n\\text{cog} & \\sim \\operatorname{Normal} (\\mu_{ij}, \\sigma_\\epsilon^2) \\\\\n\\mu_{ij}   & = \\pi_{0i} + \\pi_{1i} (\\text{age}_{ij} - 1).\n\\end{align*}\\]\nThe \\(i^{th}\\) child’s cog score at observation \\(j\\) is normally distributed, with mean \\(\\mu\\) and residuak standard deviation \\(\\sigma_{\\epsilon}\\). The mean \\(\\mu\\) is modelled as a linear function of age. The intercept will correspond to the expected score at age 1.\nNext, we consider that the children are assigned to two different group.\n\n\nearly_int<-\n  early_int|> \n  mutate(label = str_c(\"Intervetion = \", intervention)) \n\nearly_int |> \n  ggplot(aes(x = age, y = cog, color = label)) +\n  stat_smooth(aes(group = id),\n              method = \"lm\", se = F, size = 1/6) +\n  stat_smooth(method = \"lm\", se = F, size = 2) +\n  scale_color_viridis_d(option = \"B\", begin = .33, end = .67) +\n  scale_x_continuous(breaks = c(1, 1.5, 2)) +\n  ylim(50, 150) +\n  theme(legend.position = \"none\",\n        panel.grid = element_blank()) +\n  facet_wrap(~label)\n\n\n\n\nFitting the model with brms\n\n\npriors_early_1 <- prior(normal(0, 20), class = b)\n\nfit_early_1 <-\n  brm(cog ~ 0 + Intercept + age_c + intervention + age_c:intervention + \n        (1 + age_c | id),\n      prior = priors_early_1,\n      data = early_int,\n      control = list(adapt_delta = 0.95),\n      seed = 3,\n      file = \"models/fit_early_1\",\n      file_refit = \"on_change\")\n\n\n\n\n\nfit_early_1\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: cog ~ 0 + Intercept + age_c + intervention + age_c:intervention + (1 + age_c | id) \n   Data: early_int (Number of observations: 309) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 103) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)            9.72      1.17     7.63    12.21 1.00\nsd(age_c)                3.90      2.37     0.25     8.72 1.01\ncor(Intercept,age_c)    -0.48      0.35    -0.96     0.51 1.00\n                     Bulk_ESS Tail_ESS\nsd(Intercept)             830     2186\nsd(age_c)                 274      498\ncor(Intercept,age_c)     2951     1938\n\nPopulation-Level Effects: \n                      Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept               105.72      1.86   102.02   109.32 1.00\nage_c                   -19.92      1.90   -23.66   -16.21 1.00\ninterventionyes           9.79      2.41     4.91    14.61 1.00\nage_c:interventionyes     2.66      2.50    -2.27     7.59 1.00\n                      Bulk_ESS Tail_ESS\nIntercept                 1247     1818\nage_c                     2249     2811\ninterventionyes           1338     2137\nage_c:interventionyes     2395     2714\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     8.59      0.50     7.63     9.59 1.01      513     1347\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nconditional_effects(fit_early_1,\n                    \"age_c:intervention\")\n\n\n\n\n\nHow would you go about demonstrating evidence for or against a difference between the interventions?\n\nChanges in adolescent alcohol use\n\nAs part of a larger study of substance abuse, Curran, Stice, and Chassin (1997) collected three waves of longitudinal data on 82 adolescents. Each year, beginning at age 14, the teenagers completed a four-item instrument assessing their alcohol consumption during the previous year. Using an 8-point scale (ranging from 0 = “not at all” to 7 = “every day”), adolescents described the frequency with which they (1) drank beer or wine, (2) drank hard liquor, (3) had five or more drinks in a row, and (4) got drunk. The data set also includes two potential predictors of alcohol use: COA, a dichotomy indicating whether the adolescent is a child of an alcoholic parent; and PEER, a measure of alcohol use among the adolescent’s peers. This latter predictor was based on information gathered during the initial wave of data collection. Participants used a 6-point scale (ranging from 0 = “none” to 5 = “all”) to estimate the proportion of their friends who drank alcohol occasionally (one item) or regularly (a second item).\n\n\nDo individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism and early peer alcohol use.\n\n\n\nlibrary(tidyverse)\n\nalcohol <- read_csv(\"data/alcohol1_pp.csv\")\nhead(alcohol)\n\n\n# A tibble: 6 x 9\n     id   age   coa  male age_14 alcuse  peer  cpeer  ccoa\n  <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl>\n1     1    14     1     0      0   1.73 1.26   0.247 0.549\n2     1    15     1     0      1   2    1.26   0.247 0.549\n3     1    16     1     0      2   2    1.26   0.247 0.549\n4     2    14     1     1      0   0    0.894 -0.124 0.549\n5     2    15     1     1      1   0    0.894 -0.124 0.549\n6     2    16     1     1      2   1    0.894 -0.124 0.549\n\n\n\nVariable\n\n\nDescription\n\n\nid\n\n\nsubject ID\n\n\nage\n\n\nin years\n\n\ncoa\n\n\nchild of alcoholic parent (1 - yes, 0 - no)\n\n\nmale\n\n\nindicator for male\n\n\nage_14\n\n\nage - 14 (0 corresponds to age: 14)\n\n\nalcuse\n\n\nalcohol consumption\n\n\npeer\n\n\nalcohol use among peers\n\n\ncpeer, ccoa\n\n\ncentred variables\n\n\n\n\nalcohol %>%\n  filter(id %in% c(4, 14, 23, 32, 41, 56, 65, 82)) %>%\n  \n  ggplot(aes(x = age, y = alcuse)) +\n  stat_smooth(method = \"lm\", se = F) +\n  geom_point() +\n  coord_cartesian(xlim = c(13, 17),\n                  ylim = c(-1, 4)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~id, ncol = 4)\n\n\n\n\n\\[\\begin{align*}\n\\text{alcuse}_{ij} & = \\pi_{0i} + \\pi_{1i} (\\text{age}_{ij} - 14) + \\epsilon_{ij}\\\\\n\\epsilon_{ij}      & \\sim \\operatorname{Normal}(0, \\sigma_\\epsilon^2),\n\\end{align*}\\]\n\\[\\begin{align*}\n\\text{alcuse}_{ij} & = \\big [ \\gamma_{00} + \\gamma_{10} \\text{age_14}_{ij} + \\gamma_{01} \\text{coa}_i + \\gamma_{11} (\\text{coa}_i \\times \\text{age_14}_{ij}) \\big ] \\\\\n& \\;\\;\\;\\;\\; + [ \\zeta_{0i} + \\zeta_{1i} \\text{age_14}_{ij} + \\epsilon_{ij} ] \\\\\n\\epsilon_{ij} & \\sim \\operatorname{Normal} (0, \\sigma_\\epsilon^2) \\\\\n\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix} & \\sim \\operatorname{Normal} \n\\begin{pmatrix}\n\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \n\\begin{bmatrix} \\sigma_0^2 & \\sigma_{01} \\\\ \\sigma_{01} & \\sigma_1^2 \\end{bmatrix}\n\\end{pmatrix},\n\\end{align*}\\]\nUnconditional means model\n\\[\\begin{align*}\n\\text{alcuse}_{ij} & =  \\gamma_{00} +  \\zeta_{0i} + \\epsilon_{ij} \\\\\n\\epsilon_{ij}      & \\sim \\operatorname{Normal}(0, \\sigma_\\epsilon^2) \\\\\n\\zeta_{0i}         & \\sim \\operatorname{Normal}(0, \\sigma_0^2).\n\\end{align*}\\]\n\n\nget_prior(alcuse ~ 1 + (1 | id),\n          data = alcohol)\n\n\n                prior     class      coef group resp dpar nlpar bound\n student_t(3, 1, 2.5) Intercept                                      \n student_t(3, 0, 2.5)        sd                                      \n student_t(3, 0, 2.5)        sd              id                      \n student_t(3, 0, 2.5)        sd Intercept    id                      \n student_t(3, 0, 2.5)     sigma                                      \n       source\n      default\n      default\n (vectorized)\n (vectorized)\n      default\n\n\n\nfit_alcuse_1 <-\n  brm(alcuse ~ 1 + (1 | id),\n      data = alcohol,\n      file = \"models/fit_alcuse_1\",\n      file_refit = \"on_change\")\n\n\n\nUnconditional growth model\n\\[\\begin{align*}\n\\text{alcuse}_{ij} & = \\gamma_{00} + \\gamma_{10} \\text{age_14}_{ij} + \\zeta_{0i} + \\zeta_{1i} \\text{age_14}_{ij} + \\epsilon_{ij} \\\\\n\\epsilon_{ij} & \\sim \\operatorname{Normal} (0, \\sigma_\\epsilon^2) \\\\\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix} & \\sim \\operatorname{Normal} \n\\begin{pmatrix}\n\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \n\\begin{bmatrix} \\sigma_0^2 & \\sigma_{01} \\\\ \\sigma_{01} & \\sigma_1^2 \\end{bmatrix}\n\\end{pmatrix}.\n\\end{align*}\\]\n\n\nget_prior(alcuse ~ 0 + Intercept + age_14 + (1 + age_14 | id),\n          data = alcohol)\n\n\n                prior class      coef group resp dpar nlpar bound\n               (flat)     b                                      \n               (flat)     b    age_14                            \n               (flat)     b Intercept                            \n               lkj(1)   cor                                      \n               lkj(1)   cor              id                      \n student_t(3, 0, 2.5)    sd                                      \n student_t(3, 0, 2.5)    sd              id                      \n student_t(3, 0, 2.5)    sd    age_14    id                      \n student_t(3, 0, 2.5)    sd Intercept    id                      \n student_t(3, 0, 2.5) sigma                                      \n       source\n      default\n (vectorized)\n (vectorized)\n      default\n (vectorized)\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n      default\n\n\n\nfit_alcuse_2 <-\n  brm(alcuse ~ 0 + Intercept + age_14 + (1 + age_14 | id),\n      prior = c(prior(normal(0, 15), class = b)),\n      data = alcohol,\n      file = \"models/fit_alcuse_2\")\n\n\n\nEffect of COA\n\\[\\begin{align*}\n\\text{alcuse}_{ij} & = \\gamma_{00} + \\gamma_{01} \\text{coa}_i + \\gamma_{10} \\text{age_14}_{ij} + \\gamma_{11} \\text{coa}_i \\times \\text{age_14}_{ij} + \\zeta_{0i} + \\zeta_{1i} \\text{age_14}_{ij} + \\epsilon_{ij} \\\\\n\\epsilon_{ij} & \\sim \\text{Normal} (0, \\sigma_\\epsilon^2) \\\\\n\\begin{bmatrix} \\zeta_{0i} \\\\ \\zeta_{1i} \\end{bmatrix} & \\sim \\text{Normal} \n\\begin{pmatrix}\n\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \n\\begin{bmatrix} \\sigma_0^2 & \\sigma_{01} \\\\ \\sigma_{01} & \\sigma_1^2 \\end{bmatrix}\n\\end{pmatrix}.\n\\end{align*}\\]\n\n\nfit_alcuse_3 <-\n  brm(data = alcohol,\n      alcuse ~ 0 + Intercept + age_14 + coa + age_14:coa + (1 + age_14 | id),\n      prior = c(prior(normal(0, 15), class = b)),\n      file = \"models/fit_alcuse_3\")\n\n\n\n\n\nfit_alcuse_3\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: alcuse ~ 0 + Intercept + age_14 + coa + age_14:coa + (1 + age_14 | id) \n   Data: alcohol (Number of observations: 246) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 82) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)             0.70      0.10     0.51     0.90 1.01\nsd(age_14)                0.36      0.09     0.15     0.52 1.02\ncor(Intercept,age_14)    -0.10      0.29    -0.50     0.70 1.01\n                      Bulk_ESS Tail_ESS\nsd(Intercept)              947     2048\nsd(age_14)                 341      668\ncor(Intercept,age_14)      624      601\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept      0.32      0.13     0.06     0.57 1.00     2454\nage_14         0.29      0.08     0.13     0.46 1.00     3114\ncoa            0.74      0.19     0.36     1.12 1.00     2196\nage_14:coa    -0.05      0.12    -0.29     0.19 1.00     2956\n           Tail_ESS\nIntercept      2757\nage_14         2854\ncoa            2481\nage_14:coa     2883\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.61      0.05     0.52     0.72 1.01      524     1151\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nmcmc_plot(fit_alcuse_3)\n\n\n\n\n\n\nloo_alcuse_2 <- loo(fit_alcuse_2)\nloo_alcuse_3 <- loo(fit_alcuse_3)\n\n\n\n\n\nloo_compare(loo_alcuse_2, loo_alcuse_3)\n\n\n             elpd_diff se_diff\nfit_alcuse_2  0.0       0.0   \nfit_alcuse_3 -0.7       2.4   \n\n\n\nplot(loo_alcuse_3)\n\n\n\n\nTime-varying predictors\nIf we have time-varying predictor variable, it is a good idea the decompose these into a subject’specific mean (trait) and a session-by-session deviation from that mean (state).\nLet’s look at some simulated data, in which patient are assigned to either a control or a therapy (ACT) group. Patients’ wellbeing (score) is assessed over the course of 12 sessions. In addition, we have the patient-rated therapeutic alliance, which reflects how the quality of patient-therapist interactions.\n\n\n# https://raw.githubusercontent.com/awellis/learnmultilevelmodels/main/data/wellbeing.csv\nwellbeing <- read_csv(\"data/wellbeing.csv\")\n\n\n\n\n\nwellbeing |> \n  ggplot(aes(session, score, color = therapy)) +\n  geom_line() +\n  geom_point() +\n  geom_line(aes(session, alliance), linetype = 2) +\n  scale_x_continuous(breaks = seq(2, 12, by = 2)) +\n  scale_color_brewer(type = \"qual\") +\n  facet_wrap(~patient)\n\n\n\n\nWe want to predict patient’s wellbeing as a function of the therapeutic alliance, while accounting for a linear trend.\n\nHow would you specify this model, as well as unconditional models?\nAt which level is the predictor variable alliance?\n\nDecomposing time-varying predictors\nInstead of using the raw alliance variable, we will create two new variables: the average alliance, and the session-by-session deviations from the average. The average will be a patient-level (level 2) predictor, and can be used to explain variability between patients, whereas the deviations reflect fluctuations within patients at individual sessions.\n\n\nwellbeing <- wellbeing |> \n  group_by(patient) |> \n  mutate(al_between = round(mean(alliance, na.rm = TRUE), 2),\n         al_within = alliance - al_between)\n\n\n\n\n\nfit_alliance_1 <- brm(score ~ session + (1 + session| patient),\n                    data = wellbeing,\n                    file = \"models/fit_alliance_1\")\n\n\n\n\n\nfit_alliance_2 <- brm(score ~ session + al_between + al_within + \n                      (1 + session  + al_within | patient),\n                    data = wellbeing,\n                    file = \"models/fit_alliance_2\")\n\n\n\n\n\nfit_alliance_3 <- brm(score ~ session + al_within + \n                      (1 + session  + al_within | patient),\n                    data = wellbeing,\n                    file = \"models/fit_alliance_3\")\n\n\n\n\n\nfit_alliance_2\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: score ~ session + al_between + al_within + (1 + session + al_within | patient) \n   Data: wellbeing (Number of observations: 111) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~patient (Number of levels: 12) \n                         Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)                2.67      0.73     1.58     4.34 1.00\nsd(session)                  0.09      0.07     0.00     0.27 1.00\nsd(al_within)                0.90      0.57     0.05     2.21 1.00\ncor(Intercept,session)      -0.14      0.46    -0.87     0.80 1.00\ncor(Intercept,al_within)    -0.37      0.44    -0.96     0.67 1.00\ncor(session,al_within)      -0.11      0.49    -0.89     0.84 1.00\n                         Bulk_ESS Tail_ESS\nsd(Intercept)                1566     2500\nsd(session)                  1304     1738\nsd(al_within)                1661     1780\ncor(Intercept,session)       2799     2463\ncor(Intercept,al_within)     2895     2439\ncor(session,al_within)       2263     3065\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept      4.89      8.00   -10.44    21.29 1.00     1426\nsession        0.18      0.06     0.05     0.30 1.00     3139\nal_between    -0.11      1.88    -3.94     3.54 1.00     1440\nal_within     -0.72      0.50    -1.72     0.22 1.00     2778\n           Tail_ESS\nIntercept      1882\nsession        2514\nal_between     1880\nal_within      2668\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.80      0.14     1.55     2.10 1.00     3490     2939\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nKurz, A. Solomon. 2021. Applied Longitudinal Data Analysis in Brms and the Tidyverse. Version 0.0.2. https://bookdown.org/content/4253/.\n\n\nRAUDENBUSH, STEPHEN W., and WING-SHING CHAN. 1992. “Growth Curve Analysis in Accelerated Longitudinal Designs.” Journal of Research in Crime and Delinquency 29 (4): 387–411. https://doi.org/10.1177/0022427892029004001.\n\n\nSinger, Judith D., and John B. Willett. n.d. Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence. Applied Longitudinal Data Analysis. Oxford University Press. Accessed June 10, 2021. https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:05:37+02:00"
    },
    {
      "path": "popularity.html",
      "title": "Assignment 3",
      "description": "Pupil popularity\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2021-06-11T06:05:38+02:00"
    },
    {
      "path": "solution-3.html",
      "title": "Assignment 3",
      "description": "Pupil popularity and extraversion\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nDownload data\nIntercept-only model\nFirst level predictors\nSecond level predictors\nCross-level interaction\n\n\n\nShow code\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nWe’ll look at a dataset containing popularity ratings (given by classmates) and various personal characteristics of pupils in different classes. The data are available from thecompanion website of a book on multilevel analysis (“Multilevel Analysis: Techniques and Applications, Third Edition” n.d.). The code used here borrows heavily from one of the author’s website.\nDownload data\n\n\nShow code\n\npopularity <- haven::read_sav(file = \"https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav?raw=true\")\n\n\n\n\n\nShow code\n\npopularity <- popularity |> \n  select(-starts_with(\"Z\"), -Cextrav, - Ctexp, -Csex) |> \n  mutate(sex = haven::as_factor(sex),\n         pupil = as_factor(pupil),\n         class = as_factor(class))\n\npopularity\n\n\n# A tibble: 2,000 x 7\n   pupil class extrav sex    texp popular popteach\n   <fct> <fct>  <dbl> <fct> <dbl>   <dbl>    <dbl>\n 1 1     1          5 girl     24     6.3        6\n 2 2     1          7 boy      24     4.9        5\n 3 3     1          4 girl     24     5.3        6\n 4 4     1          3 girl     24     4.7        5\n 5 5     1          5 girl     24     6          6\n 6 6     1          4 boy      24     4.7        5\n 7 7     1          5 boy      24     5.9        5\n 8 8     1          4 boy      24     4.2        5\n 9 9     1          5 boy      24     5.2        5\n10 10    1          5 boy      24     3.9        3\n# … with 1,990 more rows\n\nThe variables are\n- pupil: ID   \n- class: which class are pupils in?\n- extrav: extraversion score\n- sex: girl or boy\n- texp: teacher experience\n- popular: popularity rating\n- popteach: teacher popularity\n- Zextrav: z-transformed extraversion score           \nYou want to predict pupils’ popularity using their extraversion, gender and teacher experience.\n\nIt is important to consider which the predictor variables are at. extrav and sex are level-1 predictors, which means they are variables which vary with each observation (here this means by pupils), whereas texp is a level-2 predictor—this does not vary by observation, but by class. In other words, teacher experience is an attribute of class.\n\n\nYou should center the predictor variables.\nHow many pupils are there per class?\n\n\n\nShow code\n\nglimpse(popularity)\n\n\nRows: 2,000\nColumns: 7\n$ pupil    <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ class    <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ extrav   <dbl> 5, 7, 4, 3, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 6, 4, …\n$ sex      <fct> girl, boy, girl, girl, girl, boy, boy, boy, boy, bo…\n$ texp     <dbl> 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,…\n$ popular  <dbl> 6.3, 4.9, 5.3, 4.7, 6.0, 4.7, 5.9, 4.2, 5.2, 3.9, 5…\n$ popteach <dbl> 6, 5, 6, 5, 6, 5, 5, 5, 5, 3, 5, 5, 5, 6, 5, 5, 2, …\n\n\n\nShow code\n\npopularity <- popularity |> \n  mutate(teacher_exp = texp - mean(texp))\n\n\n\n\n\nShow code\n\npopularity |> \n  count(class)\n\n\n# A tibble: 100 x 2\n   class     n\n   <fct> <int>\n 1 1        20\n 2 2        20\n 3 3        18\n 4 4        23\n 5 5        21\n 6 6        20\n 7 7        21\n 8 8        20\n 9 9        20\n10 10       24\n# … with 90 more rows\n\n\n\nShow code\n\npopularity |> \n  group_by(class) |> \n  n_groups()\n\n\n[1] 100\n\nWe can plot the data, without taking into account the hierarchical structure.\n\n\nShow code\n\npopularity |> \n  ggplot(aes(x = extrav,\n           y = popular,\n           color = class,\n           group = class)) + \n  geom_point(size     = 1.2,\n             alpha    = .8,\n             position = \"jitter\") +\n  theme(legend.position = \"none\") +\n  scale_color_viridis_d() +\n  labs(title = \"Popularity ~ Extraversion\")\n\n\n\n\nThe goal here it estimate the average effect of extraversion on popularity. However, we assume that this effect will vary by class, and it might also depend on the pupils’ sex. Furthermore, classes may vary by how many years of experience a teacher has. We assume that this might be important.\nIntercept-only model\nStart by fitting an intercept-only model. With this we will predict\n\n\nShow code\n\nfit1 <- brm(popular ~ 1 + (1 | class),\n            data = popularity,\n            file = \"models/pop-fit1\")\n\n\n\nIn this model, we are estimating the average the average popularity over classes, as well as the deviation from this average for each class.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]}, \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\nFirst level predictors\nNow you can add some level 1 predictors, e.g. sex, extrav. You can use the update() so that you don’t have to rerun the compilation steps.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nfit1 |> \n  update(. ~ . + sex, \n         prior = prior(normal(0, 2), class = b),\n         newdata = popularity)\n\n\n\nThis is equivalent to\n\n\nShow code\n\nfit2 <- brm(popular ~ 1 + sex + extrav + (1|class),  \n              prior = prior(normal(0, 2), class = b),\n              data = popularity, \n            iter = 4000,\n            file = \"models/pop-fit2\") \n\n\n\nSecond level predictors\nNow add the the level-2 predictor teacher experience.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\gamma_{0}^{\\alpha} + \\gamma_{1}^{\\alpha}(\\operatorname{teacher\\_exp}), \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nfit3 <- fit2 |> update(. ~ . + teacher_exp,\n                       file = \"models/pop-fit3\",\n                       newdata = popularity)\n\n\n\nor equivalently\n\n\nShow code\n\nfit3 <- brm(popular ~ 1 + sex + extrav + teacher_exp + (1 | class),  \n            prior = prior(normal(0, 2), class = b),\n            data = popularity,\n            file = \"models/pop-fit3\") \n\n\n\nNow it’s time for some plot.\n\n\nShow code\n\nfit2 |> mcmc_plot()\n\n\n\n\n\n\nShow code\n\nfit3 |> mcmc_plot()\n\n\n\n\nModel comparisons\n\n\nShow code\n\nloo2 <- loo(fit2)\nloo3 <- loo(fit3)\n\n\n\n\n\nShow code\n\nloo_compare(loo2, loo3)\n\n\n     elpd_diff se_diff\nfit3  0.0       0.0   \nfit2 -1.6       2.5   \n\n\n\nShow code\n\nbayes_R2(fit2)\n\n\n    Estimate   Est.Error      Q2.5     Q97.5\nR2 0.6903738 0.006662371 0.6768908 0.7027676\n\nShow code\n\nbayes_R2(fit3)\n\n\n    Estimate  Est.Error      Q2.5     Q97.5\nR2 0.6905302 0.00680099 0.6767647 0.7035434\n\n\n\nShow code\n\nperformance::r2_bayes(fit2)\n\n\n# Bayesian R2 with Standard Error\n\n  Conditional R2: 0.691 (89% CI [0.680, 0.701])\n     Marginal R2: 0.388 (89% CI [0.372, 0.405])\n\nShow code\n\nperformance::r2_bayes(fit3)\n\n\n# Bayesian R2 with Standard Error\n\n  Conditional R2: 0.691 (89% CI [0.680, 0.701])\n     Marginal R2: 0.510 (89% CI [0.485, 0.536])\n\nCross-level interaction\nLet teacher experience interact with extraversion. This is what’s known as a cross-level interaction; extraversion is a predictor of the level 1 units (pupils), whereas teacher experience is s predictor at level 2 (classes). This can be verified by looking at the dataframe—teacher experience does not have one unique value per observation, but instead for each class.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2j[i]}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{2j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\gamma_{0}^{\\alpha} + \\gamma_{1}^{\\alpha}(\\operatorname{texp}) \\\\\n      &\\gamma^{\\beta_{2}}_{0} + \\gamma^{\\beta_{2}}_{1}(\\operatorname{texp})\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{2j}} \\\\ \n     \\rho_{\\beta_{2j}\\alpha_{j}} & \\sigma^2_{\\beta_{2j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nShow code\n\nmodel5 <- brm(popular ~ 1 + sex + extrav + texp + extrav:texp + \n                (1 + extrav | class), \n              prior = prior(normal(0, 2), class = b),\n              data  = popularity)\n\n\n\n\nYou can attempt to decide which models fit better than others by doing posterior predictive checks.\n\n\n\n\n“Multilevel Analysis: Techniques and Applications, Third Edition.” n.d. Routledge & CRC Press. Accessed May 29, 2021. https://www.routledge.com/Multilevel-Analysis-Techniques-and-Applications-Third-Edition/Hox-Moerbeek-Schoot/p/book/9781138121362.\n\n\n\n\n",
      "last_modified": "2021-06-11T06:06:05+02:00"
    },
    {
      "path": "test.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Nora Jones",
          "url": "https://example.com/norajones"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\n\nShow code\n\nknitr::opts_chunk$set()\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\nShow code\n\nc(\"dogs\", \"cats\", \"rats\") |>\n      {\\(x) grepl(\"at\", x)}()\n\n\n[1] FALSE  TRUE  TRUE\n\n\n\n\n",
      "last_modified": "2021-06-11T06:06:06+02:00"
    },
    {
      "path": "topics.html",
      "title": "Topics",
      "description": "Bayesian multilevel modelling workshop 2021\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-21-2021",
      "contents": "\n\nContents\nTopics\nPlanned contents\nYour expectations/questions\n\n\nTopics\nPlanned contents\nThis workshop is designed to provide a practical introduction to basic and advanced multilevel models. Participants will learn how to fit models using both maximum likelihood and Bayesian methods, although the focus will be on Bayesian parameter estimation and model comparison. We will start with a short introduction to multilevel modelling and to Bayesian statistics in general, followed by an introduction to Stan, a probabilistic programming language for fitting Bayesian models. We will then learn how to use the R package brms, which provides a user-friendly interface to Stan. The package supports a wide range of response distributions and modelling options, and allows us to fit multilevel generalized linear models. Depending on participants’ wishes, we will take a closer look at modelling various types of data, such as choices, response times, ordinal or longitudinal data.\nSpecific topics include:\nBayesian inference: an introduction\nBayesian parameter estimation\nModel comparison & hypothesis testing\nBayes factors\nOut-of-sample predictive accuracy (LOO)\n\nSpecifying multilevel generalized linear models\nUnderstanding statistical models through data simulation\nA principled Bayesian workflow for data analysis\nYour expectations/questions\nSince most of you expressed an interest in Bayesian statistics, we will mostly multilevel generalized regression models from this perspective.\nSpecific topics\nadvantages of Bayesian over frequentist statistics\nhow to select priors\npreparing data\nbinary (choice) data\nresponse times\nrepeated measures and other hierarchical (multilevel) designs, inlcuding longitudinal data\ncrossed random effects, e.g. lexical decision tasks\ncategorical variables\nmoderation / mediation\nSEM (structural equation models)\nmodel comparison / hypothesis testing in mixed effects models\ndyadic data\nnonlinear regression\n\n\n\n",
      "last_modified": "2021-06-11T06:06:06+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
