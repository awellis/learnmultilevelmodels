{
  "articles": [
    {
      "path": "about.html",
      "title": "About this blog",
      "description": "Some additional details about the blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-05-29T13:47:45+02:00"
    },
    {
      "path": "assignment-1.html",
      "title": "Assignment 1",
      "description": "Estimating means and standard deviations\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-24-2021",
      "contents": "\n\nContents\nGenerate data\n\nBefore completing this assignment, please read the brms walkthrough.\nWe fitted a gaussian model to some simple generated data. However, in the model we assumed that both groups had the same standard deviations. This assumption is not really necessary, however, as we can easily fit a model in which we allow both mean and standard deviation to vary between groups.\n\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nGenerate data\n\n\nN <- 10\n\nmean_a <- 20.0\nsigma_a <- 2.0\n\nmean_b <- 16.0\nsigma_b <- 1.5\n\nset.seed(12)\nd <- tibble(A = rnorm(N, mean_a, sigma_a),\n            B = rnorm(N, mean_b, sigma_b))\nd <- d |>\n  pivot_longer(everything(), names_to = \"group\",\n                values_to = \"score\") |> \n  mutate(group = as_factor(group)) |> \n  arrange(group)\n\n\n\nbrms allows us easily fit both the main parameter (in this case the mean), as well as further distributional parameters. We simply need to wrap the formula in the bf() function. Therefore, instead of the formula score ~ group we can use this bf(score ~ group, sigma ~ group).\n\n\nscore ~ group\n\n\n\nCan be replaced with:\n\n\nbf(score ~ group, sigma ~ group)\n\n\n\n\nPerform the steps described in the walkthrough, but this time for the model that allows both \\(\\mu\\) and \\(\\sigma\\) to vary. Does this model perform well? Are you able to recover the true parameter values?\nNOTE: The standard deviation must be positive; therefore we are predicting log(sigma) with our linear predictor. To recover the parameter on the original scale, you need to use the inverse function, which is the exponential function exp().\nTry it out; if you get stuck, you can always ask questions on Zulip.\n\n\n\nShow code\n\nget_prior(bf(score ~ group, sigma ~ group),\n          data = d)\n\n\n                   prior     class   coef group resp  dpar nlpar\n                  (flat)         b                              \n                  (flat)         b groupB                       \n student_t(3, 16.9, 2.5) Intercept                              \n                  (flat)         b                   sigma      \n                  (flat)         b groupB            sigma      \n    student_t(3, 0, 2.5) Intercept                   sigma      \n bound       source\n            default\n       (vectorized)\n            default\n       (vectorized)\n       (vectorized)\n            default\n\n\n\nShow code\n\nm3 <- brm(bf(score ~ group, sigma ~ group),\n          prior = prior(normal(0, 4), class = b),\n          data = d, \n          file = \"models/m3\")\n\n\n\n\n\nShow code\n\nconditional_effects(m3)\n\n\n\n\n\n\nShow code\n\npp_check(m3)\n\n\n\n\n\n\nShow code\n\npp_check(m3, type = \"dens_overlay_grouped\", group = \"group\")\n\n\n\n\n\n\n\n",
      "last_modified": "2021-05-29T13:47:53+02:00"
    },
    {
      "path": "assignment-2.html",
      "title": "Assignment 2",
      "description": "Parameter estimation in clustered data\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\n\n\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nExercise 1\nUse the simulate_treament() function to generate data. Vary the parameter settings, and then attempt to recover the known parameters using brm().\nExercise 2\nUse the simulate_treament() function to generate data. Give your data to a colleague and they will give you theirs in return. Try to recover the (unknown to you) parameters using brm().\nExercise 3\nLoad the dataset sleepstudy from the lme4 package. These are data from a sleep deprivation study, in which the average reaction time per day (in milliseconds) was recorded.\nHave a look at the data, and then try to estimate the effect of day on reaction time.\n\nIt’s always a good idea to plot the data before you do anything else.\n\n\n\nlibrary(lme4)\nglimpse(sleepstudy)\n\n\nRows: 180\nColumns: 3\n$ Reaction <dbl> 249.5600, 258.7047, 250.8006, 321.4398, 356.8519, 4…\n$ Days     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, …\n$ Subject  <fct> 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 3…\n\n\n\n\n",
      "last_modified": "2021-05-29T13:47:54+02:00"
    },
    {
      "path": "assignment-3.html",
      "title": "Assignment 3",
      "description": "Pupil popularity and extraversion\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nDownload data\nIntercept-only model\nFirst level predictors\nCross-level interaction\n\n\n\n\nWe’ll look at a dataset containing popularity ratings (given by classmates) and various personal characteristics of pupils in different classes. The data are available from thecompanion website of a book on multilevel analysis (“Multilevel Analysis: Techniques and Applications, Third Edition” n.d.).\nDownload data\n\n\n\n\n# A tibble: 2,000 x 7\n   pupil class extrav sex    texp popular popteach\n   <dbl> <dbl>  <dbl> <fct> <dbl>   <dbl>    <dbl>\n 1     1     1      5 girl     24     6.3        6\n 2     2     1      7 boy      24     4.9        5\n 3     3     1      4 girl     24     5.3        6\n 4     4     1      3 girl     24     4.7        5\n 5     5     1      5 girl     24     6          6\n 6     6     1      4 boy      24     4.7        5\n 7     7     1      5 boy      24     5.9        5\n 8     8     1      4 boy      24     4.2        5\n 9     9     1      5 boy      24     5.2        5\n10    10     1      5 boy      24     3.9        3\n# … with 1,990 more rows\n\nThe variables are\n- pupil: ID\n- class: which class are pupils in?\n- extrav: extraversion score\n- sex: gender\n- texp: teacher experience\n- popular: popularity rating\n- popteach: teacher popularity\n- Zextrav: z-transformed extraversion score           \nYou want to predict pupils’ popularity using their extraversion, gender and teacher experience.\n\nYou should center the predictor variables.\nHow many pupils are there per class?\n\n\n# A tibble: 100 x 2\n# Groups:   class [100]\n   class     n\n   <dbl> <int>\n 1     1    20\n 2     2    20\n 3     3    18\n 4     4    23\n 5     5    21\n 6     6    20\n 7     7    21\n 8     8    20\n 9     9    20\n10    10    24\n# … with 90 more rows\n\n\n\n\nIntercept-only model\nStart by fitting an intercept-only model.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]}, \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\n\nFirst level predictors\nNow you can add some level 1 predictors, e.g. sex, extrav. You can use the update() so that you don’t have to rerun the compilation steps.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\n\nThis is equivalent to\n\n\n\nNow add both sex and extrav as varying effecs.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2j[i]}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j} \\\\\n      &\\beta_{2j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}} \\\\\n      &\\mu_{\\beta_{2j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{ccc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} & \\rho_{\\alpha_{j}\\beta_{2j}} \\\\ \n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}} & \\rho_{\\beta_{1j}\\beta_{2j}} \\\\ \n     \\rho_{\\beta_{2j}\\alpha_{j}} & \\rho_{\\beta_{2j}\\beta_{1j}} & \\sigma^2_{\\beta_{2j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\nCross-level interaction\nAdd teacher experience as a predictor. Let it interact with extraversion. This is what’s known as a cross-level interaction; extraversion is a predictor of the level 1 units (pupils), whereas teacher experience is s predictor at level 2 (classes). This can be verified by looking at the dataframe—teacher experience does not have one unique value per observation, but instead for each class.\n\\[\n\\begin{aligned}\n  \\operatorname{popular}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{sex}_{\\operatorname{girl}}) + \\beta_{2j[i]}(\\operatorname{extrav}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{2j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\gamma_{0}^{\\alpha} + \\gamma_{1}^{\\alpha}(\\operatorname{texp}) \\\\\n      &\\gamma^{\\beta_{2}}_{0} + \\gamma^{\\beta_{2}}_{1}(\\operatorname{texp})\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{2j}} \\\\ \n     \\rho_{\\beta_{2j}\\alpha_{j}} & \\sigma^2_{\\beta_{2j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for class j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\n\n\nYou can attempt to decide which models fit better than others by doing posterior predictive checks.\n\n\n\n\n“Multilevel Analysis: Techniques and Applications, Third Edition.” n.d. Routledge & CRC Press. Accessed May 29, 2021. https://www.routledge.com/Multilevel-Analysis-Techniques-and-Applications-Third-Edition/Hox-Moerbeek-Schoot/p/book/9781138121362.\n\n\n\n\n",
      "last_modified": "2021-05-29T13:47:56+02:00"
    },
    {
      "path": "assignment-4.html",
      "title": "Assignment 4",
      "description": "Effect of tDCS stimulation on episodic memory\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\nContents\nEffect of tDCS on memory\n\n\n\n\nEffect of tDCS on memory\nYou are going to analyze data from a study in which 34 elderly subjects were given anodal (activating) tDCS over their left tempero-parietal junction (TPJ). Subjects were instructed to learn association between images and pseudo-words (data were inspired by Antonenko et al. (2019)).\nEpisodic memory is measured by percentage of correctly recalled word-image pairings. We also have response times for correct decisions.\nEach subject was tested 5 times in the TPJ stimulation condition, and a further 5 times in a sham stimulation condition.\nThe variables in the dataset are:\nsubject: subject ID\nstimulation: TPJ or sham (control)\nblock: block\nage: age\ncorrect: accuracy per block\nrt: mean RTs for correct responses\nYou are mainly interested in whether recall ability is better during the TPJ stimulation condition than during sham.\n\n\n\n\nRows: 340\nColumns: 6\n$ subject     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ stimulation <chr> \"control\", \"control\", \"control\", \"control\", \"con…\n$ block       <dbl> 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, …\n$ age         <dbl> 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 67, 67, …\n$ correct     <dbl> 0.8, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.6, 0.6, 0.8…\n$ rt          <dbl> 1.650923, 1.537246, 1.235620, 1.671189, 1.408333…\n\n\n\n\n\nspecify a linear model\nspecify a null model\nestimate a Bayes factor for the effect of TPJ stimulation\nusing the Savage-Dickey density ratio test\nusing the bridge sampling method\n\ncontrol for subjects’ age\n\n\n\n\nAntonenko, Daria, Dayana Hayek, Justus Netzband, Ulrike Grittner, and Agnes Flöel. 2019. “tDCS-Induced Episodic Memory Enhancement and Its Association with Functional Network Coupling in Older Adults.” Scientific Reports 9 (1, 1): 2273. https://doi.org/10.1038/s41598-019-38630-7.\n\n\n\n\n",
      "last_modified": "2021-05-29T13:47:57+02:00"
    },
    {
      "path": "assignment-5.html",
      "title": "Assignment 4",
      "description": "The N400 effect\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\n\n\n\nThis example is borrowed the companion website for the Shravan Vasishth, Bruno Nicenboim, and Daniel Schad (n.d.).\n\n\n\n\n\n\n\n# A tibble: 2,863 x 7\n    subj cloze  item  n400 cloze_ans     N c_cloze\n   <dbl> <dbl> <dbl> <dbl>     <dbl> <dbl>   <dbl>\n 1     1  0        1  7.08         0    44  -0.476\n 2     1  0.03     2 -0.68         1    44  -0.446\n 3     1  1        3  1.39        44    44   0.524\n 4     1  0.93     4 22.8         41    44   0.454\n 5     1  0        5  1.61         0    44  -0.476\n 6     1  0        6  3.01         0    44  -0.476\n 7     1  0.8      7  9.96        35    44   0.324\n 8     1  0.03     9 -1.85         1    44  -0.446\n 9     1  0.03    10  8.73         1    44  -0.446\n10     1  0.87    11 10.9         38    44   0.394\n# … with 2,853 more rows\n\n\n\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB \\\n  foo.c\nclang -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Users/andrew/Library/R/4.1/library/Rcpp/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppEigen/include/unsupported\"  -I\"/Users/andrew/Library/R/4.1/library/BH/include\" -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/src/\"  -I\"/Users/andrew/Library/R/4.1/library/StanHeaders/include/\"  -I\"/Users/andrew/Library/R/4.1/library/RcppParallel/include/\"  -I\"/Users/andrew/Library/R/4.1/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include   -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:88:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Users/andrew/Library/R/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Dense:1:\n/Users/andrew/Library/R/4.1/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\n\n\nShravan Vasishth, Bruno Nicenboim, and Daniel Schad. n.d. An Introduction to Bayesian Data Analysis for Cognitive Science. Accessed May 29, 2021. https://vasishth.github.io/Bayes_CogSci/.\n\n\n\n\n",
      "last_modified": "2021-05-29T13:48:28+02:00"
    },
    {
      "path": "index.html",
      "title": "Learn multilevel models workshop",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-05-29T13:48:29+02:00"
    },
    {
      "path": "intro.html",
      "title": "Introduction",
      "description": "Bayesian multilevel modelling workshop 2021\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-21-2021",
      "contents": "\n\nContents\nWhat is this workshop about?\nOutline\nFriday, May 21\nFriday, May 28\nSaturday, May 29\nFriday, June 4\n\nPrerequisites\nSoftware\nAssignments\nZulip\n\nWhat is this workshop about?\nThis workshop will focus on hierarchical (multilevel) regression models from various angles. While reading your expectations and questions regarding this workshop, it became clear that all of your points can be approached within the same framework, i.e. Bayesian hierarchical generalized regression models. We will spend a lot of time learning to understand and specify these types of models. However, we will focus mainly on learning how to implement and work with these models, rather than spending time looking at the formal math. Here, I will follow the approach taken by McElreath (2020), who emphasises that even mathematicians may have trouble understanding something until they see a working algorithm.\nTherefore, this workshop will be very hands-on. Everything we do will be illustrated with working code examples, and you are encouraged to try every single line of code for yourself.\nOutline\nFriday, May 21\nWe will start with a general introduction to Bayesian inference, followed by an intro to the programming language Stan, and the R packages rstan and brms. Since we will be working almost exclusively with brms therafter, it is important to spend a bit of time here.\nWe will dive straight into Bayesian inference here, without spending too much time on frequentist methods and the differences between the two approaches (we will focus on this mode when we get to model comparisons).\nWe will then explore how models can be implemented as general (or generalized) linear models, and we will introduce multilevel models as a natural way of modelling reapeated measurements.\nFriday, May 28\nSaturday, May 29\nFriday, June 4\nPrerequisites\nBasic knowledge of regression models and R is a necessity. I strongly recommend that you prepare for the workshop by working through this online script: https://methodenlehre.github.io/intro-to-rstats. Previous exposure to multilevel models and longitudinal models would be helpful, but is not strictly necessary. Knowledge of Bayesian statistics is not required.\nSoftware\nWe will be using R and RStudio, as well a variety of R packages. It is advisable to ensure that you have a working R installation before the workshop starts, and that you install the two R packages rstan and brms. Detailed instructions for installing these packages on all platforms can be found at https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started and https://paul-buerkner.github.io/brms.\nAssignments\nWe will focus on learning new topics during the morning sessions, and participants should work through the assignments during the afternoon sessions. Participants are also encouraged to bring their own datasets.\nZulip\nThe Zulip chat server will be our communicatin platform for this workshop. We will use this for questions, assignments, troubleshooting, etc. Zulip can be used for synchronous or asynchronous chats, and has very good threading capabilities. Zulip is also pretty easy to use, and uses Markdown for message formatting. This means that you can use Markdown to format code and equations.\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd Edition. 2nd ed. CRC Press. http://xcelab.net/rm/statistical-rethinking/.\n\n\n\n\n",
      "last_modified": "2021-05-29T13:48:29+02:00"
    },
    {
      "path": "popularity.html",
      "title": "Assignment 3",
      "description": "Pupil popularity\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-28-2021",
      "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2021-05-29T13:48:30+02:00"
    },
    {
      "path": "test.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Nora Jones",
          "url": "https://example.com/norajones"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\n\nShow code\n\nknitr::opts_chunk$set()\n\n\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\nShow code\n\nc(\"dogs\", \"cats\", \"rats\") |>\n      {\\(x) grepl(\"at\", x)}()\n\n\n[1] FALSE  TRUE  TRUE\n\n\n\n\n",
      "last_modified": "2021-05-29T13:48:30+02:00"
    },
    {
      "path": "topics.html",
      "title": "Topics",
      "description": "Bayesian multilevel modelling workshop 2021\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "05-21-2021",
      "contents": "\n\nContents\nTopics\nPlanned contents\nYour expectations/questions\n\n\nTopics\nPlanned contents\nThis workshop is designed to provide a practical introduction to basic and advanced multilevel models. Participants will learn how to fit models using both maximum likelihood and Bayesian methods, although the focus will be on Bayesian parameter estimation and model comparison. We will start with a short introduction to multilevel modelling and to Bayesian statistics in general, followed by an introduction to Stan, a probabilistic programming language for fitting Bayesian models. We will then learn how to use the R package brms, which provides a user-friendly interface to Stan. The package supports a wide range of response distributions and modelling options, and allows us to fit multilevel generalized linear models. Depending on participants’ wishes, we will take a closer look at modelling various types of data, such as choices, response times, ordinal or longitudinal data.\nSpecific topics include:\nBayesian inference: an introduction\nBayesian parameter estimation\nModel comparison & hypothesis testing\nBayes factors\nOut-of-sample predictive accuracy (LOO)\n\nSpecifying multilevel generalized linear models\nUnderstanding statistical models through data simulation\nA principled Bayesian workflow for data analysis\nYour expectations/questions\nSince most of you expressed an interest in Bayesian statistics, we will mostly multilevel generalized regression models from this perspective.\nSpecific topics\nadvantages of Bayesian over frequentist statistics\nhow to select priors\npreparing data\nbinary (choice) data\nresponse times\nrepeated measures and other hierarchical (multilevel) designs, inlcuding longitudinal data\ncrossed random effects, e.g. lexical decision tasks\ncategorical variables\nmoderation / mediation\nSEM (structural equation models)\nmodel comparison / hypothesis testing in mixed effects models\ndyadic data\nnonlinear regression\n\n\n\n",
      "last_modified": "2021-05-29T13:48:31+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
