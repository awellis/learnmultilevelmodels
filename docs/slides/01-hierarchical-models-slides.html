<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Intro to Bayesian Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Andrew Ellis" />
    <meta name="date" content="2021-05-28" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#bf616a"],"pen_size":3,"eraser_size":30}) })</script>
    <script src="libs/mark.js/mark.min.js"></script>
    <link href="libs/xaringanExtra-search/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-right","caseSensitive":false,"showIcon":false,"autoSearch":true}) })</script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link href="libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
    <script src="libs/pagedtable/js/pagedtable.js"></script>
    <link rel="stylesheet" href="css/xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="css/slides-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Intro to Bayesian Statistics
## Part 3 <br/> Hierarchical models
### Andrew Ellis
### Bayesian multilevel modelling workshop 2021
### 2021-05-28

---







layout: true
  
&lt;!-- Home icon --&gt;
&lt;div class="my-footer"&gt;
&lt;span&gt;
&lt;a href="https://awellis.github.io/learnmultilevelmodels/" target="_blank"&gt;<svg aria-hidden="true" role="img" viewBox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#0F4C81;overflow:visible;position:relative;"><path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"/></svg>&lt;/a&gt; Graduate School workshop 2021
&lt;/span&gt;
&lt;/div&gt;


&lt;!-- Name (left) --&gt;
&lt;!-- &lt;div class="my-footer"&gt; --&gt;
&lt;!-- &lt;span&gt; --&gt;
&lt;!-- Andrew Ellis - &lt;a href="https://kogpsy.github.io/neuroscicomplab" target="_blank"&gt;kogpsy.github.io/neuroscicomplab&lt;/a&gt; --&gt;
&lt;!-- &lt;/span&gt; --&gt;
&lt;!-- &lt;/div&gt; --&gt;

&lt;!-- slide separator (for xaringan) --&gt;
---





## Hierarchical Models

&lt;!-- library(lmerTest) --&gt;
&lt;!-- options(contrasts=c('contr.sum', 'contr.poly')) --&gt;
&lt;!-- anova(lmer(y ~ x + (1|subj),data=myDat),ddf="Kenward-Roger") --&gt;

&lt;!-- library(afex) --&gt;
&lt;!-- mixed(y ~ x + (1|subj), type=3,method="KR",data=myDat)  --&gt;


How can repeated measurements be taken into account?

--



---

class: middle

.pull-left-narrow[
  .huge-blue-number[1]
]
.pull-right-wide[
  .larger[
  Estimating Means
  ]
]

---

## Another IQ Example

This time we have 3 subjects, and 3 measurements from each subject.

.footnote[
Lee, Michael D., and Eric-Jan Wagenmakers. Bayesian Cognitive Modeling: A Practical Course. Cambridge: Cambridge University Press, 2014. https://doi.org/10.1017/CBO9781139087759.
]


.panelset[
.panel[.panel-name[Create data]


```r
IQwide &lt;- tribble(
  ~A, ~B, ~C,
  110, 105, 115,
  105, 112, 108,
  102, 113, 130
)
```
]
.panel[.panel-name[Pivot longer]


```r
IQdata &lt;- IQwide |&gt; 
  pivot_longer(everything(), names_to = "Person", values_to = "IQ") |&gt; 
  mutate(Person = as_factor(Person)) |&gt; 
  arrange(Person)
```
]
.panel[.panel-name[Data]


```r
library(kableExtra)
IQdata |&gt; 
  kbl() |&gt; 
  scroll_box(width = "500px", height = "200px")
```

&lt;div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:200px; overflow-x: scroll; width:500px; "&gt;&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;"&gt; Person &lt;/th&gt;
   &lt;th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;"&gt; IQ &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 110 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 105 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 102 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 105 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 112 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 113 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; C &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 115 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; C &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 108 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; C &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 130 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;

]
]

---

## Point Estimates





```r
se &lt;- function(x) sd(x)/sqrt(length(x))

IQdata |&gt; 
  group_by(Person) |&gt; 
  summarise(mean = mean(IQ),
            sd = sd(IQ),
            se = se(IQ))
```

```
## # A tibble: 3 x 4
##   Person  mean    sd    se
##   &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 A       106.  4.04  2.33
## 2 B       110   4.36  2.52
## 3 C       118. 11.2   6.49
```

---


```r
IQdata |&gt; 
  ggplot(aes(Person, IQ)) +
  geom_point()
```

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-6-1.png" width="100%" /&gt;


---


.discussion[

- How would you analyse these data? 

]

<div class="countdown" id="timer_60b0500e" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


## Parameter estimation


Our goal is to estimate the 3 latent IQs, and the group mean. We assume that for each person, the measurements are normally distributed around that person's latent IQ. For simplicity, we assume a common standard deviation.

$$ IQ_{i} \sim \mathcal{N}(\mu_j, \sigma^2) $$



 
We have 3 possibilies:

- __No pooling:__ We can pretend that all people are independent of each other.

- __Complete pooling:__ We can pretend that all observations are from the same person.

- __Partial pooling:__ We can take into account that we have multiple observations for each person. We can use these to estimate each person's mean, but we assume that these 3 people are similar to each other, i.e. they are samples from a super-population of people. Therefore, information we have from one person can inform other people's estimates.



---

## Partial Pooling Model

The partial pooling model can be written as

$$
`\begin{aligned}
  \operatorname{IQ}_{i}  &amp;\sim N \left(\alpha_{j}, \sigma^2 \right) \\
    \alpha_{j}  &amp;\sim N \left(\mu_{\alpha}, \sigma^2_{\alpha} \right)
    \text{, for person j = 1,} \dots \text{,J}
\end{aligned}`
$$ 

where `\(\mu_{\alpha}\)` is the population level effect, and the `\(\alpha_{j}\)` are the latent IQ scores for each Person.

---

## No pooling




```r
library(brms)
get_prior(IQ ~ 0 + Person,
          data = IQdata)
```

```
##                 prior class    coef group resp dpar nlpar bound       source
##                (flat)     b                                          default
##                (flat)     b PersonA                             (vectorized)
##                (flat)     b PersonB                             (vectorized)
##                (flat)     b PersonC                             (vectorized)
##  student_t(3, 0, 7.4) sigma                                          default
```


---

## No pooling


```r
m_no_pool &lt;- brm(IQ ~ 0 + Person,
                 data = IQdata,
                 file = "models/m_no_pool")
```


---

## Complete pooling



```r
get_prior(IQ ~ 1,
          data = IQdata)
```

```
##                   prior     class coef group resp dpar nlpar bound  source
##  student_t(3, 110, 7.4) Intercept                                  default
##    student_t(3, 0, 7.4)     sigma                                  default
```


---

## Complete pooling


```r
m_comp_pool &lt;-  brm(IQ ~ 1,
                 data = IQdata,
                 file = "models/m_comp_pool")
```


---

## Partial pooling



```r
get_prior(IQ ~ 1 + (1 | Person),
                 data = IQdata)
```

```
##                   prior     class      coef  group resp dpar nlpar bound
##  student_t(3, 110, 7.4) Intercept                                       
##    student_t(3, 0, 7.4)        sd                                       
##    student_t(3, 0, 7.4)        sd           Person                      
##    student_t(3, 0, 7.4)        sd Intercept Person                      
##    student_t(3, 0, 7.4)     sigma                                       
##        source
##       default
##       default
##  (vectorized)
##  (vectorized)
##       default
```


---

## Partial pooling


&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-14-1.png" width="100%" /&gt;


---

## Partial pooling


```r
m_part_pool &lt;-  brm(IQ ~ 1 + (1 | Person),
                 data = IQdata,
                 file = "models/m_part_pool")
```




---


.panelset[
.panel[.panel-name[No Pooling]


```r
m_no_pool
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: IQ ~ 0 + Person 
##    Data: IQdata (Number of observations: 9) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## PersonA   105.67      4.90    95.63   115.37 1.00     2708     1960
## PersonB   110.03      4.96   100.05   119.93 1.00     3531     2408
## PersonC   117.66      4.92   107.87   127.13 1.00     3645     2285
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     8.17      2.55     4.76    14.42 1.00     2152     2189
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

]

.panel[.panel-name[Complete Pooling]

```r
m_comp_pool
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: IQ ~ 1 
##    Data: IQdata (Number of observations: 9) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   110.93      2.71   105.68   116.47 1.00     2390     2126
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     8.78      2.22     5.64    14.04 1.00     2397     2354
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

]
.panel[.panel-name[Partial Pooling]


```r
m_part_pool
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: IQ ~ 1 + (1 | Person) 
##    Data: IQdata (Number of observations: 9) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~Person (Number of levels: 3) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     5.00      3.90     0.18    15.33 1.00     1187     1793
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   111.03      3.52   104.03   118.26 1.00     1537     1491
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     8.09      2.29     4.88    13.45 1.00     1733     2515
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```
]
]

---

## Partial Pooling


```r
f &lt;- fixef(m_part_pool, summary = FALSE)
r &lt;- ranef(m_part_pool, summary = FALSE)
```




```r
library(tidybayes)

get_variables(m_part_pool)
```

```
##  [1] "b_Intercept"           "sd_Person__Intercept"  "sigma"                
##  [4] "r_Person[A,Intercept]" "r_Person[B,Intercept]" "r_Person[C,Intercept]"
##  [7] "lp__"                  "accept_stat__"         "stepsize__"           
## [10] "treedepth__"           "n_leapfrog__"          "divergent__"          
## [13] "energy__"
```

```r
person_effects &lt;- m_part_pool |&gt;
  spread_draws(b_Intercept, r_Person[Person, Intercept]) |&gt;
  # add the grand mean to the person-specific deviations
  mutate(mu = b_Intercept + r_Person)
```


---


```r
person_effects |&gt; 
  median_qi(mu)
```

```
## # A tibble: 3 x 8
## # Groups:   Person [3]
##   Person Intercept    mu .lower .upper .width .point .interval
##   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 A      Intercept  109.   100.   116.   0.95 median qi       
## 2 B      Intercept  111.   104.   118.   0.95 median qi       
## 3 C      Intercept  114.   106.   122.   0.95 median qi
```


```r
fixef(m_no_pool)
```

```
##         Estimate Est.Error      Q2.5    Q97.5
## PersonA 105.6677  4.903999  95.63449 115.3670
## PersonB 110.0306  4.962230 100.04958 119.9328
## PersonC 117.6587  4.917794 107.87280 127.1344
```

---

.panelset[
.panel[.panel-name[Plot Code]


```r
person_effects |&gt; 
  ggplot(aes(mu, Person)) +
  stat_halfeye(fill = "#A2BF8A") +
  geom_vline(xintercept = fixef(m_part_pool)[1, 1], color = "#839496", size = 1) +
  geom_vline(xintercept = fixef(m_part_pool)[1, 3:4], color = "#839496", linetype = 2) +
  labs(x = expression("Subject specific means"),
       y = "Subjects") +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0)) 
```
]
.panel[.panel-name[Plot]

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-24-1.png" width="100%" /&gt;
]
]



---

## Partial Pooling vs No Pooling


Due to the hierarchical nature of the model, individual estimate are pulled toward the group mean. This means that the will tend to be less extreme. This is known as "shrinkage".


.panelset[
.panel[.panel-name[Plot Code]


```r
col &lt;- viridis::viridis(3, begin = 0.2, end = 0.8)

person_effects |&gt; 
  ggplot(aes(mu, Person, fill = Person)) +
  stat_halfeye(alpha = 0.6) +
  geom_vline(xintercept = fixef(m_part_pool)[1, 1], color = "#ECCC87", 
             size = 1) +
  geom_vline(xintercept = fixef(m_no_pool)[1, 1], color = col[1], 
             size = 1) +
  geom_vline(xintercept = fixef(m_no_pool)[2, 1], color = col[2], 
             size = 1) +
   geom_vline(xintercept = fixef(m_no_pool)[3, 1], color = col[3], 
              size = 1) +
  scale_fill_viridis_d(begin = 0.2, end = 0.8) +
  labs(x = expression("Subject specific means),
       y = "Subjects") +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0)) 
```
]
.panel[.panel-name[Plot]

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-26-1.png" width="100%" /&gt;
]
]





---

class: middle

.pull-left-narrow[
  .huge-blue-number[2]
]
.pull-right-wide[
  .larger[
  Mixed Models
  ]
]

---

.panelset[
.panel[.panel-name[Create dataset]



```r
library(tidyverse)

intervention &lt;- rep(c('treat', 'control'), each = 5)
pre &lt;- c(20, 10, 60, 20, 10, 50, 10, 40, 20, 10)
post &lt;- c(70, 50, 90, 60, 50, 20, 10, 30, 50, 10)
```


```r
dwide &lt;- tibble(id = factor(1:10), 
            intervention, pre, post) |&gt; 
  mutate(diff = post - pre,
         id = as_factor(id), 
         intervention =  factor(intervention, levels = c("control", "treat")))
```
]
.panel[.panel-name[Dataframe]

```r
dwide |&gt; 
  rmarkdown::paged_table()
```

&lt;div data-pagedtable="false"&gt;
  &lt;script data-pagedtable-source type="application/json"&gt;
{"columns":[{"label":["id"],"name":[1],"type":["fct"],"align":["left"]},{"label":["intervention"],"name":[2],"type":["fct"],"align":["left"]},{"label":["pre"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["post"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["diff"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"treat","3":"20","4":"70","5":"50"},{"1":"2","2":"treat","3":"10","4":"50","5":"40"},{"1":"3","2":"treat","3":"60","4":"90","5":"30"},{"1":"4","2":"treat","3":"20","4":"60","5":"40"},{"1":"5","2":"treat","3":"10","4":"50","5":"40"},{"1":"6","2":"control","3":"50","4":"20","5":"-30"},{"1":"7","2":"control","3":"10","4":"10","5":"0"},{"1":"8","2":"control","3":"40","4":"30","5":"-10"},{"1":"9","2":"control","3":"20","4":"50","5":"30"},{"1":"10","2":"control","3":"10","4":"10","5":"0"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  &lt;/script&gt;
&lt;/div&gt;

]]

---


```r
d &lt;- dwide |&gt; 
  select(-diff) |&gt; 
  pivot_longer(cols = pre:post, names_to = "time", values_to = "score") |&gt; 
  mutate(time = as_factor(time))

d |&gt; 
  rmarkdown::paged_table()
```

&lt;div data-pagedtable="false"&gt;
  &lt;script data-pagedtable-source type="application/json"&gt;
{"columns":[{"label":["id"],"name":[1],"type":["fct"],"align":["left"]},{"label":["intervention"],"name":[2],"type":["fct"],"align":["left"]},{"label":["time"],"name":[3],"type":["fct"],"align":["left"]},{"label":["score"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"treat","3":"pre","4":"20"},{"1":"1","2":"treat","3":"post","4":"70"},{"1":"2","2":"treat","3":"pre","4":"10"},{"1":"2","2":"treat","3":"post","4":"50"},{"1":"3","2":"treat","3":"pre","4":"60"},{"1":"3","2":"treat","3":"post","4":"90"},{"1":"4","2":"treat","3":"pre","4":"20"},{"1":"4","2":"treat","3":"post","4":"60"},{"1":"5","2":"treat","3":"pre","4":"10"},{"1":"5","2":"treat","3":"post","4":"50"},{"1":"6","2":"control","3":"pre","4":"50"},{"1":"6","2":"control","3":"post","4":"20"},{"1":"7","2":"control","3":"pre","4":"10"},{"1":"7","2":"control","3":"post","4":"10"},{"1":"8","2":"control","3":"pre","4":"40"},{"1":"8","2":"control","3":"post","4":"30"},{"1":"9","2":"control","3":"pre","4":"20"},{"1":"9","2":"control","3":"post","4":"50"},{"1":"10","2":"control","3":"pre","4":"10"},{"1":"10","2":"control","3":"post","4":"10"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  &lt;/script&gt;
&lt;/div&gt;


---


We have 10 subjects.

.panelset[
.panel[.panel-name[Subjects]



```r
d |&gt; 
  summarize(id = n_distinct(id))
```

```
## # A tibble: 1 x 1
##      id
##   &lt;int&gt;
## 1    10
```
]

.panel[.panel-name[Trials per subject]

with 2 observations per subject.



```r
d |&gt; 
  group_by(id, intervention) |&gt; 
  count() |&gt; 
  rmarkdown::paged_table()
```

&lt;div data-pagedtable="false"&gt;
  &lt;script data-pagedtable-source type="application/json"&gt;
{"columns":[{"label":["id"],"name":[1],"type":["fct"],"align":["left"]},{"label":["intervention"],"name":[2],"type":["fct"],"align":["left"]},{"label":["n"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"treat","3":"2"},{"1":"2","2":"treat","3":"2"},{"1":"3","2":"treat","3":"2"},{"1":"4","2":"treat","3":"2"},{"1":"5","2":"treat","3":"2"},{"1":"6","2":"control","3":"2"},{"1":"7","2":"control","3":"2"},{"1":"8","2":"control","3":"2"},{"1":"9","2":"control","3":"2"},{"1":"10","2":"control","3":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  &lt;/script&gt;
&lt;/div&gt;
]
]

---

.discussion[
How would you analyse these data?
]

<div class="countdown" id="timer_60b05007" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

## Summarize Data

.panelset[
.panel[.panel-name[Standard error function]


```r
se &lt;- function(x) sd(x)/sqrt(length(x))
```

]
.panel[.panel-name[Summarize (long)]


```r
d |&gt; 
  group_by(intervention, time) |&gt; 
  summarise(mean = mean(score),
            sd = sd(score),
            se = se(score))
```

```
## # A tibble: 4 x 5
## # Groups:   intervention [2]
##   intervention time   mean    sd    se
##   &lt;fct&gt;        &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 control      pre      26  18.2  8.12
## 2 control      post     24  16.7  7.48
## 3 treat        pre      24  20.7  9.27
## 4 treat        post     64  16.7  7.48
```

]

.panel[.panel-name[Summarize (wide)]


```r
dwide |&gt; 
  group_by(intervention) |&gt; 
  summarise(mean = mean(diff),
            sd = sd(diff),
            se = se(diff))
```

```
## # A tibble: 2 x 4
##   intervention  mean    sd    se
##   &lt;fct&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 control         -2 21.7   9.70
## 2 treat           40  7.07  3.16
```
]

]

---

.panelset[
.panel[.panel-name[Plot Code]


```r
d |&gt; 
  ggplot(aes(time, score, color = intervention)) +
  geom_line(aes(group = id), linetype = 1, size = 1) +
  geom_point(size = 4) +
  scale_color_viridis_d(end = 0.8) +
  theme_bw()
```

]

.panel[.panel-name[Plot]

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-38-1.png" width="100%" /&gt;

]
]



---

## Welch Test


```r
t.test(diff ~ intervention,
       data = dwide, 
       var.equal = FALSE)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  diff by intervention
## t = -4.1184, df = 4.8415, p-value = 0.009835
## alternative hypothesis: true difference in means between group control and group treat is not equal to 0
## 95 percent confidence interval:
##  -68.47507 -15.52493
## sample estimates:
## mean in group control   mean in group treat 
##                    -2                    40
```

---


## Mixed Model



.panelset[
.panel[.panel-name[Model Code]


```r
library(lme4)
lme_model &lt;- lmer(score ~ intervention * time + (1|id), 
                  data = d)
```

]

.panel[.panel-name[Model summary]


```r
lme_model |&gt; 
  sjPlot::tab_model()
```

&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;&amp;nbsp;&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;score&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;Predictors&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;Estimates&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;CI&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;p&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;(Intercept)&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;26.00&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;10.08&amp;nbsp;&amp;ndash;&amp;nbsp;41.92&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&lt;strong&gt;0.001&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;intervention [treat]&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&amp;#45;2.00&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&amp;#45;24.52&amp;nbsp;&amp;ndash;&amp;nbsp;20.52&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;0.862&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;time [post]&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&amp;#45;2.00&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&amp;#45;16.13&amp;nbsp;&amp;ndash;&amp;nbsp;12.13&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;0.782&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;intervention [treat] *&lt;br&gt;time [post]&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;42.00&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;22.01&amp;nbsp;&amp;ndash;&amp;nbsp;61.99&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;"&gt;Random Effects&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;&amp;sigma;&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;130.00&lt;/td&gt;

&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;&amp;tau;&lt;sub&gt;00&lt;/sub&gt; &lt;sub&gt;id&lt;/sub&gt;&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;200.00&lt;/td&gt;

&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;ICC&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;0.61&lt;/td&gt;

&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;N &lt;sub&gt;id&lt;/sub&gt;&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;10&lt;/td&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;Observations&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;Marginal R&lt;sup&gt;2&lt;/sup&gt; / Conditional R&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;0.481 / 0.796&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
]

.panel[.panel-name[Model equations]

$$
`\begin{aligned}
  \operatorname{score}_{i}  &amp;\sim N \left(\alpha_{j[i]} + \beta_{1}(\operatorname{time}_{\operatorname{post}}), \sigma^2 \right) \\
    \alpha_{j}  &amp;\sim N \left(\gamma_{0}^{\alpha} + \gamma_{1}^{\alpha}(\operatorname{intervention}_{\operatorname{treat}}) + \gamma_{2}^{\alpha}(\operatorname{intervention}_{\operatorname{treat}} \times \operatorname{time}_{\operatorname{post}}), \sigma^2_{\alpha_{j}} \right)
    \text{, for id j = 1,} \dots \text{,J}
\end{aligned}`
$$
]]

---



```r
library(afex)
mixed(score ~ intervention * time + (1|id), 
      type = 3, method = "KR",
      data = d)
```

```
## Fitting one lmer() model. [DONE]
## Calculating p-values. [DONE]
```

```
## Mixed Model Anova Table (Type 3 tests, KR-method)
## 
## Model: score ~ intervention * time + (1 | id)
## Data: d
##              Effect   df        F p.value
## 1      intervention 1, 8     3.41    .102
## 2              time 1, 8 13.88 **    .006
## 3 intervention:time 1, 8 16.96 **    .003
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
```

---


## What is going on here?


```r
mm &lt;- model.matrix(~ intervention * time,
             data = d)
head(mm)
```

```
##   (Intercept) interventiontreat timepost interventiontreat:timepost
## 1           1                 1        0                          0
## 2           1                 1        1                          1
## 3           1                 1        0                          0
## 4           1                 1        1                          1
## 5           1                 1        0                          0
## 6           1                 1        1                          1
```

---

## Explanation

- We are predicting the mean of the outcome variable `score` with a linear model. 

- The mean is decomposed into 
 + population-level effects: `intervention * time`
 + group-level effects (a deviation from the average for every person): `(1 | id)`

---


## Using `brms`


.panelset[
.panel[.panel-name[get_prior]


```r
library(brms)

priors1 &lt;- get_prior(score ~ intervention * time + (1|id),
          data = d)
```
]
.panel[.panel-name[Priors]


```
## # A tibble: 9 x 4
##   prior                    class     coef                         group
##   &lt;chr&gt;                    &lt;chr&gt;     &lt;chr&gt;                        &lt;chr&gt;
## 1 ""                       b         ""                           ""   
## 2 ""                       b         "interventiontreat"          ""   
## 3 ""                       b         "interventiontreat:timepost" ""   
## 4 ""                       b         "timepost"                   ""   
## 5 "student_t(3, 25, 22.2)" Intercept ""                           ""   
## 6 "student_t(3, 0, 22.2)"  sd        ""                           ""   
## 7 ""                       sd        ""                           "id" 
## 8 ""                       sd        "Intercept"                  "id" 
## 9 "student_t(3, 0, 22.2)"  sigma     ""                           ""
```

]
]

---



```r
m2 &lt;- brm(score ~ intervention*time + (1 | id),
          prior = prior(normal(0, 50), class = b),
          data = d,
          control = list(adapt_delta = 0.9),
          file =  "models/04-treat-time") 
```

---


```r
summary(m2)
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: score ~ intervention * time + (1 | id) 
##    Data: d (Number of observations: 20) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~id (Number of levels: 10) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    14.08      6.31     2.05    27.59 1.00      806      955
## 
## Population-Level Effects: 
##                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                     24.54      8.99     6.19    41.83 1.00     1699
## interventiontreat             -0.65     12.66   -25.31    24.65 1.00     1711
## timepost                      -0.75      8.50   -17.23    17.00 1.00     2771
## interventiontreat:timepost    39.38     11.61    15.30    61.64 1.00     2381
##                            Tail_ESS
## Intercept                      2366
## interventiontreat              2017
## timepost                       2203
## interventiontreat:timepost     2059
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    13.55      3.75     8.16    21.99 1.00      921     1514
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```


---


```r
m2 |&gt; 
  mcmc_plot("b_")
```

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-48-1.png" width="100%" /&gt;

                                                                                                                                                                                    
---


```r
ce &lt;- conditional_effects(m2, effects = "intervention:time")
```




```r
ce
```

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-50-1.png" width="100%" /&gt;

---


```r
plot(ce, plot = FALSE)[[1]] + 
  scale_color_brewer(type = "qual") +
  scale_fill_brewer(type = "qual")
```

&lt;img src="01-hierarchical-models-slides_files/figure-html/unnamed-chunk-51-1.png" width="100%" /&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:10",
"countIncrementalSlides": false,
"slideNumberFormat": "<div class=\"progress-bar-container\">\n  <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n  </div>\n</div>"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
