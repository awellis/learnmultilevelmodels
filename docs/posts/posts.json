[
  {
    "path": "posts/2021-05-29-bayes-factor-group-difference/",
    "title": "Estimating a Bayes factor for a difference in means",
    "description": "Using Savage-Dickey and bridge sampling",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": "https://github.com/awellis"
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "multilevel models",
      "Bayes factor"
    ],
    "contents": "\n\nContents\nBayes factor for difference in means\n\nBayes factor for difference in means\nWe are going to look at data from a study in which children with ADHD were compared to a control group in terms of their working memory capacity\n\n\nlibrary(tidyverse)\nnback <- read_csv(\"https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/adhd-nback.csv\")\n\n\n\nDie grouping variable group should be converted to a factor.\n\n\nnback <- nback %>% \n  mutate(group = as_factor(group),\n         group = fct_relevel(group, \"control\"))\n\n\n\nA directed Welch test result in a p-value of approx. 0.07. We cannot reject the null hypothesis.\n\n\nt.test(rt ~ group,\n       data = nback,\n       alternative = \"less\")\n\n\n\n    Welch Two Sample t-test\n\ndata:  rt by group\nt = -1.5282, df = 28.57, p-value = 0.06873\nalternative hypothesis: true difference in means between group control and group adhd is less than 0\n95 percent confidence interval:\n       -Inf 0.01757687\nsample estimates:\nmean in group control    mean in group adhd \n             1.153130              1.309528 \n\nWe now want to perform a Bayesian model comparison using a Bayes factor.\n\nExercise 1 Estimate an intercept and a group difference. Use a normal(0, 1) for the group difference.\n\n\n\nsummary(m1)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ group \n   Data: nback1 (Number of observations: 51) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.15      0.06     1.03     1.28 1.00     3543     2601\ngroupadhd     0.16      0.10    -0.04     0.35 1.00     3581     2679\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.34      0.04     0.27     0.41 1.00     3673     2572\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nThe population level effects Intercept and groudadhd represent the expected mean of the control group, and the expected difference between groups. The parameter has a mean of \\(0.16\\) a \\(95%\\) credible interval of \\([-0.04, 0.35]\\).\nIn der Lösung von Übung 2 habe ich gezeigt, wie Sie mit der hypothesis() Funktion die Wahrscheinlichkeit erhalten, dass der Unterschied zwischen den Gruppen positiv ist.\n\nExercise 2\nUse the hypothesis() function to obtain the probability that the parameter is \\(>0\\).\nSave the output of hypothesis() and plot it (using plot().\n\n\n\nh1 <- m1 %>% \n  hypothesis(\"groupadhd > 0\")\n\nh1\n\n\nHypothesis Tests for class b:\n       Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (groupadhd) > 0     0.16       0.1        0     0.31      17.18\n  Post.Prob Star\n1      0.94     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nWir untersuchen hier, welcher Anteil der Posterior Verteilung des Gruppenunterschieds groupadhd positiv ist. Das Evidence Ratio Evid.Ratio gibt den Anteil der Fläche unter der Kurve, welcher positiv ist, geteilt durch den negativen Anteil. Wir erhalten ein Evidence Ratio von \\(17.18\\), was bedeutet, dass der positive Anteil der Fläche \\(17.18\\) mal grösser ist als der negative Anteil.\nFolglich ist es \\(17.18\\) mal wahrscheinlicher, dass der Parameter positiv ist, als dass er negativ ist. Mit dieser Information können wir die Wahrscheinlichkeit, dass der Parameter positiv ist, berechnen. Wir müssen lediglich die Wahrscheinlichkeit \\(p_+\\) finden, für die gilt: \\(\\frac{p_+}{1-p_+} = 17.18\\). Nach Umformen erhalten wir \\(p_+ = 17.18/(1 + 17.18) = 0.945\\). DIes ist genau die Wahrscheinlichkeit, welhe wir unter Post.Prob erhalten.\n\n\np_pos <- 17.18 / (1 + 17.18)\np_pos\n\n\n[1] 0.9449945\n\n\n\nplot(h1)\n\n\n\n\n\nAufgabe 3\nSchätzen Sie das Modell von Aufgabe 1 nochmals, aber diesmal mit dem zusätzlichen Argument sample_prior = TRUE. Speichern Sie dies als m2.\n\n\n\nm2 <- brm(rt ~ group,\n          prior = priors,\n          sample_prior = TRUE,\n          data = nback1,\n          file = \"models/exc4-m2\")\n\n\n\nDies führt dazu, dass Sie neben den Samples aus den Posterior Verteilung auch Samples aus den Prior Verteilungen erhalten. Diese können Sie für den Unterschied zwischen den Gruppen so grafisch darstellen.\n\n\nm2 %>% \n  mcmc_plot(c(\"b_groupadhd\", \"prior_b\"))\n\n\n\n\nWir sehen in dieser Grafik die Prior und die Posterior Verteilungen von b_groupadhd, also das, was wir anfangs geglaubt haben, und das, was wir glauben, nachdem wir die Daten berücksichtigt haben.\n\nAufgabe 4\nTesten Sie nun die Nullhypothese, dass der Gruppenunterschied Null sein sollte, mit der hypothesis() Funktion (Savage-Dickey Density Ratio).\nSpeichern Sie den Ouput als h2.\nSchauen Sie sich den Output an (mit print(h2) oder einfach h2.)\nEvidence Ratio Evid.Ratio ist der Bayes Factor \\(BF_{01}\\). Der Output der hypothesis() Funktion ist übrigens eine Liste; das Evid.Ratio kann mit h2$hypothesis$Evid.Ratio extrahiert werden. Speichern Sie es als BF01.\nErklären Sie in Worten, was der \\(BF_{01}\\) bedeutet. Wofür haben Sie Evidenz gefunden?\nZeigen Sie auch den Bayes Factor \\(BF_{10}\\) (Tipp: dies ist ganz einfach, wenn Sie \\(BF_{01}\\) haben). Was sagt uns \\(BF_{10}\\)?\n\n\n\nh2 <- m2 %>% \n  hypothesis(\"groupadhd = 0\")\nh2\n\n\nHypothesis Tests for class b:\n       Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (groupadhd) = 0     0.16       0.1    -0.03     0.34       2.63\n  Post.Prob Star\n1      0.72     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\n\nBF01 <- h2$hypothesis$Evid.Ratio\nBF01\n\n\n[1] 2.62944\n\nDer Bayes Factor \\(BF_{01}\\) gibt an, um wieviel wahrscheinlicher die Daten unter der Nullhypothese als unter der Alternativhypothese sind. Die Alternativhypothese entspricht unserem Prior, der besagt, dass der Unterschied zwischen den Gruppen mit 95% Sicherheit zwischen -2 und 2 liegt. Dieser Prior ist scheinbar nicht besonder gut, denn unter der Nullhypothese, welche behauptet, dass der Parameter genau 0 ist, sind die Daten ca. 2.6 mal wahrscheinlicher als unter der Alternativhypothese. Wir erhalten also hier Evidenz für die Nullhypothese, obwohl wir uns fas 95% sicher, dass der Parameter, wenn er geschätzt wird, positiv ist.\nDer Bayes Factor für die Alternativhypothse beträgt \\(0.38\\).\n\n\nBF10 <- 1/BF01\nBF10\n\n\n[1] 0.3803091\n\n\nAufgabe 5\nStellen Sie den Ouput von hypothesis() mit plot() grafisch dar.\n\nWir sehen, dass der WErt 0 unter dem Posterior eine höhere Wahrscheinlichkeit als unter dem Prior hat.\n\nOptionale Aufgabe: Wie erhalten Sie einen grösseren Bayes Factor für die Alternativhypothese \\(BF_{10}\\)?\n\nWir können versuchen, einen sinnvolleren Prior für unsere Alternativhypothese zu defnieren. Als erstes könnten wir, wenn Informationen aus vorherigen Studien haben, erwarten dass der Effekt klein sein. Dies berücksichtigen wir mit einer kleineren Standardabweichung von \\(0.1\\). Ausserdem erwarten wir, dass der Effekt positiv wird. Dies können wir ausdrücken, in dem wir eine Untergrenze von 0 für die Prior Verteilung setzen (lower bound). Wenn wir beides komnbinieren, erhalten wir folgenden Prior: prior(normal(0, 0.1), lb = 0). Dies enstpricht einer halben Normalverteilung, mit einer Standardabweichung von \\(0.1\\).\n\n\nm3 <- brm(rt ~ group,\n          prior = prior(normal(0, 0.1), lb = 0),\n          sample_prior = TRUE,\n          data = nback1,\n          file = \"models/exc4-m3\")\n\n\n\nWir können wieder Prior und Posterior grafisch darstellen. Der Prior erlaubt jetzt nur noch positive Werte.\n\n\nm3 %>% \n  mcmc_plot(c(\"b_groupadhd\", \"prior_b\"))\n\n\n\n\n\n\nh3 <- m3 %>% \n  hypothesis(\"groupadhd = 0\")\nh3\n\n\nHypothesis Tests for class b:\n       Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (groupadhd) = 0      0.1      0.06     0.01     0.22       0.42\n  Post.Prob Star\n1       0.3    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nWir erhalten nun einen Bayes Factor von $0.42 für die Nullhypothese. Dies bedeutet, dass nun die Daten unter der Alternativhypothese wahrscheinlicher sind.\n\n\nBF01alt <- h3$hypothesis$Evid.Ratio\nBF01alt\n\n\n[1] 0.423604\n\nDies ist einfacher als \\(BF_{10}\\) auszudrücken:\n\n\nBF10alt <- 1/BF01alt\nBF10alt\n\n\n[1] 2.360695\n\nWir erhalten nun also einen Bayes Factor von \\(2.36\\) für die Alternativhypothese.\nDies illustriert, dass ein Bayes Factor ausdrückt, wie gut ein e Prior Verteilung die Daten vorhersagen kann. Hypothesen entpsrechen im Bayesianischen Kontext Prior Verteilungen, und folglich müssen wir mit unseren Priors genau unsere Hypothesen ausdrücken können. Der zweite Bayes Factor \\(BF_{10} = 2.36\\) entspricht also unserer Erwartung, dass der Gruppenunterschied klein aber positiv ist.\n\n\n\n",
    "preview": "posts/2021-05-29-bayes-factor-group-difference/distill-preview.png",
    "last_modified": "2021-05-29T13:47:20+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-29-more-multilevel-models/",
    "title": "Multilevel formula syntax",
    "description": "Extended multilevel formula syntax and types of clusters",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": "https://github.com/awellis"
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "multilevel models"
    ],
    "contents": "\n\nContents\nTypes of clusters\nCrossed\nNested\nExtended multilevel formula syntax\n\n\n\n\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nTypes of clusters\nSo far we have looked at simple hierachical structures. For example, we have considered repeated measures on subjects at two time points, or over the course of several days.\nMultilevel models allow us take complex hierarchical structures into account when modelling data—for instance. we might have data from pupils nested within classes and schools, we might have two separate grouping variable that are crossed, such as subjects and word stimuli in an experiment.\nCrossed\nImagine that we are testing 3 subjects in an experiment, and each subject is shown each of 10 stimuli.\n\n\nsubject_id <- str_c(\"subj_\", 1:3)\nitem_id <- 1:10\n\n\n\n\n\ncrossing(subject_id, item_id)\n\n\n# A tibble: 30 x 2\n   subject_id item_id\n   <chr>        <int>\n 1 subj_1           1\n 2 subj_1           2\n 3 subj_1           3\n 4 subj_1           4\n 5 subj_1           5\n 6 subj_1           6\n 7 subj_1           7\n 8 subj_1           8\n 9 subj_1           9\n10 subj_1          10\n# … with 20 more rows\n\nIn this case we might want to take into account that both subjects and items can be considered as sources of variance, and that the observations can be clustered by both subjects and item. Every subject and every item appears multiple times in the dataset, and each subject is presented with all the items. In this case, subjects and items are crossed.\nIn a traditional analysis, it is commonplace to aggregate over one of the clusters while computing estimates for the other. For instance, when computing subject-specific means, we might simply ignore the items by aggregating over them.\nHowever, this can lead to aggregation artefacts, and systematically ignores aources of variation (Baayen, Davidson, and Bates 2008).\nIn a multilevel model, we can instead simultaneously model both sources of variability as separate cluster.\nIf we are predicting a response variable in different conditions, we can include these crossed varying effects using the following notation.\nVarying intercepts\n\n\nresponse ~ 1 + condition + (1 | subject) + (1 | item)\n\n\n\nor, equivalently\n\n\nresponse ~ 1 + condition + (1 | subject + item)\n\n\n\nVarying intercepts and slopes\nNote that here the intercept is automatically added to the formula.\n\n\nresponse ~ condition + (condition | subject) + (condition | item)\n\n\n\nExample\nFor example, Wagenmakers and Brown (2007) had subjects perform a lexical decision task in two conditions, speeded and accuracy, in which the instructions were to decide either as quickly or as accurately as posssible whether a string of letters was a word or a non-word. The response variable were response times and choices.\n\n\nlibrary(rtdists)\ndata(speed_acc) \n\nspeed_acc <- speed_acc %>%\n  as_tibble() |> \n  select(-censor, -block)\n\n\ndf_speed_acc <- speed_acc %>% \n   # remove rt under 180 ms and above 3000 ms\n  filter(rt > 0.18, rt < 3) %>% \n   # convert to character\n  mutate(across(c(stim_cat, response), as.character),\n         correct = as.numeric(stim_cat == response),\n         across(c(stim_cat, response), as_factor)) \n\n\n\n\n\ndf_speed_acc\n\n\n# A tibble: 31,355 x 8\n   id    condition stim  stim_cat frequency   response    rt correct\n   <fct> <fct>     <fct> <fct>    <fct>       <fct>    <dbl>   <dbl>\n 1 1     speed     5015  nonword  nw_low      nonword  0.7         1\n 2 1     speed     3623  word     very_low    nonword  0.392       0\n 3 1     speed     6481  nonword  nw_very_low nonword  0.46        1\n 4 1     speed     3305  word     very_low    word     0.455       1\n 5 1     speed     2244  word     low         nonword  0.505       0\n 6 1     speed     4468  nonword  nw_high     nonword  0.773       1\n 7 1     speed     1047  word     high        word     0.39        1\n 8 1     speed     5711  nonword  nw_low      word     0.587       0\n 9 1     speed     5036  nonword  nw_low      nonword  0.603       1\n10 1     speed     1111  word     high        word     0.435       1\n# … with 31,345 more rows\n\nWe are interested in the subject and stimulus IDs as sources of variability, and the differences in accuracy between instruction conditions.\nVarying intercept model\n\n\nbrm(correct ~ condition + (1 | id) + (1 | stim),\n    family = bernoulli(),\n    data = df_speed_acc)\n\n\n\nVarying intercept and slope model\n\n\nbrm(correct ~ condition + (condition | id) + (condition | stim),\n    family = bernoulli(),\n    data = df_speed_acc)\n\n\n\nNested\nScholastic aptitude tests are given multiple times to students (repeated observations nested within students), and students are nested within schools. Schools in turn can be nested within districts. Here, students are said to be nested within schools, meaning that each school contains students unique to that school.\nA further example could be therapists working with several different patients.\nFor example, to model varying effects for therapists nested within patients, we can can use the following syntax.\n\n\nresponse ~ condition + (condition | therapist/patient)\n\n\n\nThis is expanded to\n\n\nresponse ~ condition + (condition | therapist) + (condition | therapist:patient)\n\n\n\nThe : operator creates a new grouping factor that consists of the combined levels of therapist and patient.\n\n\nnested <- tibble(\n  patient = c(rep(\"A\",2), rep(\"B\",2), rep(\"C\",2), rep(\"D\",2)),\n  therapist  = c(rep(\"GE\", 4), rep(\"DF\", 4))\n)\n\n\n\nExtended multilevel formula syntax\nThis is explained in Bürkner (2018) and in the vignettes for the brms package.\n\nYou can access this by entering vignette(\"brms_multilevel\") in the R console.\nThe syntax in brms is very close to that introduced by lme4 (Bates et al. 2015). However, brms extend the syntax so that nore complex models cab be expressed.\nIn general, the syntax has the form\n\n\nresponse ~ pterms + (gterms | group)\n\n\n\nThe pterms part contains the population-level effects. The gterms part contains so called group-level effects that are assumed to vary within levels of a grouping variable\nFor example, (1 | group), is the simplest possible mixed-model formula, where each level of the grouping factor, group, has its own varying intercept, which can be thought of in two ways:\nas a deviation \\(\\alpha_j\\) from the average intercept \\(\\alpha\\). The \\(\\alpha_j\\) terms have the distribution \\(\\alpha_j \\sim \\mathcal{N}(0, \\sigma_{\\alpha})\\).\nas a random variate drawn from the distribution \\(\\alpha_j \\sim \\mathcal{N}(\\alpha, \\sigma_{\\alpha})\\)\nThe two are equivalent (you can always remove the mean from a normal distribution and add it to a zero mean random variate), but 1) emphasizes the decomposition into two components, whereas 2) emphasizes the hierarchical structure.\nIn addition to the lme4 inspired syntax, brms offers several extensions to the formula syntax.\nGrouping terms\nVarying effects can be grouped using the gr() function, with the argument by specifying sub-populations of the groups. For each level of the by variable, a separate variance-covariance matrix will be fitted.\nFor example, the following code fits varying intercepts for patients, but separately for each treatment.\n\n\nresponse ~ 1 + (1 | gr(patient, by = \"treatment\"))\n\n\n\nMulti-membership grouping terms\nVarying effects can also be members of several groups—this is taken care of with the mm() function. As an example, pupils might change schools during the term, meaning that they are member of both school1 and school2. We can also take into account the amount of time spent at each school using the weights argument.\n\nresponse ~ x1 + (1 | mm(school1, school2, weights = cbind(w1, w2)\n\nCorrelation between varying effects\nIf you are predicting family-specific (distributional) parameters, and you are including varying effects for a grouping variable, you might want to model a correlation between these effects. You can do by including the term |s|, where s can be any arbitrary identifier.\n\n\nbf(response ~ 1 + (1 |s| subject),\n   sigma ~ 1 + (1 |s| subject))\n\n\n\nIf on the other hand you don’t want to estimate the correlation between varying intercepts and varying slopes, you can omit this by leaving out the identifier between the | |.\n\n\nresponse ~ 1 + condition + (1 || subject)\n\n\n\n\n\n\nBaayen, R. H., D. J. Davidson, and D. M. Bates. 2008. “Mixed-Effects Modeling with Crossed Random Effects for Subjects and Items.” Journal of Memory and Language, Special issue: Emerging Data Analysis, 59 (4): 390–412. https://doi.org/10.1016/j.jml.2007.12.005.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using Lme4.” Journal of Statistical Software 67 (1). https://doi.org/10.18637/jss.v067.i01.\n\n\nBürkner, Paul-Christian. 2018. “Advanced Bayesian Multilevel Modeling with the R Package Brms.” The R Journal 10 (1): 395. https://doi.org/10.32614/RJ-2018-017.\n\n\nWagenmakers, Eric-Jan, and Scott Brown. 2007. “On the Linear Relation Between the Mean and the Standard Deviation of a Response Time Distribution.” Psychological Review 114 (3): 830–41. https://doi.org/10.1037/0033-295X.114.3.830.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-05-29T09:24:44+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-28-multilevelmodels/",
    "title": "Multilevel models",
    "description": "Parameter estimation in clustered data",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": "https://github.com/awellis"
      }
    ],
    "date": "2021-05-28",
    "categories": [
      "multilevel models"
    ],
    "contents": "\n\nContents\nPopulation-level effects\nHierarchical model\nMultilevel example\n\n\nI am using the native pipe operator, which is new to R 4.10. This pipe operator is written as a | followed by a >. In this document, the operator is printed as |>, due to the fact that I am using font ligatures. If the pipe doesn’t work for you, simply replace it with the older pipe %>%.\n\n\n\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nWe now explore the difference between fitting a model with population-level effects and a mdoel with varying effects to the same data.\nWe’ll generate some normally distributed data consisting of three conditions, with means of 0, 1 and 2. Each group has standard deviation of 0.5. We’ll draw 20 observations per condition.\nNote that we haven’t anything about the structure in the data, so these could be three independent samples, or the could be data from three subjects in one condition (even though I have called the grouping variable condition).\n\n\nset.seed(5)\n\nn_obs <- 20\nn_conditions <-  3\ncondition_means <- c(0, 1, 2)\nsigma <- 0.5\n\nd <- tibble(condition = rep(LETTERS[1:n_conditions], n_obs),\n            response = rnorm(n_obs * n_conditions, condition_means, sigma)) |> \n  arrange(condition)\n\n\n\n\n\np1 <- d |> \n  ggplot(aes(response, condition, color = condition)) +\n  geom_point( size = 2) +\n  scale_color_brewer(type = \"qual\")\n\np1\n\n\n\n\nWe can compute the condition mean and SD, and then add these to the plot.\n\n\ncondition_means <- d |> \n  group_by(condition) |> \n  summarise(mean = mean(response),\n            sd = sd(response))\n\n\n\n\n\np1 +\n  geom_point(aes(mean, condition, color = condition), \n             data = condition_means, \n             size = 6)\n\n\n\n\nPopulation-level effects\nLet’s first assume that the data are from independent samples. We want to estimate the three condition means, with the goal of comparing these. Since none of the these conditions is an obvious reference category, let’s just estimate all three means.\n\n\nformula1 <- response ~ 0 + condition\n\n\n\nThe statistical formula can be written as:\n\\[\n\\operatorname{response} = \\beta_{\\operatorname{A}}(\\operatorname{condition}_{\\operatorname{A}}) + \\beta_{\\operatorname{B}}(\\operatorname{condition}_{\\operatorname{B}}) + \\beta_{\\operatorname{C}}(\\operatorname{condition}_{\\operatorname{C}}) + \\epsilon\n\\]\nThis states that the expected value of the response variable is either \\(\\beta_{\\operatorname{A}}\\), \\(\\beta_{\\operatorname{B}}\\) or \\(\\beta_{\\operatorname{C}}\\), since these are indicator variables.\nWe can inspect the default priors.\n\n\nget_prior(formula1, data = d) |> \n  as_tibble() |> select(1:4)\n\n\n# A tibble: 5 x 4\n  prior                  class coef         group\n  <chr>                  <chr> <chr>        <chr>\n1 \"\"                     b     \"\"           \"\"   \n2 \"\"                     b     \"conditionA\" \"\"   \n3 \"\"                     b     \"conditionB\" \"\"   \n4 \"\"                     b     \"conditionC\" \"\"   \n5 \"student_t(3, 0, 2.5)\" sigma \"\"           \"\"   \n\nThe priors on the regression coefficients are flat. This should be avoided, so we’ll use normal distributions centred at 1, which is just the overall mean.\n\n\npriors1 <- prior(normal(1, 1), class = b)\n\ntibble(x = seq(-3, 5, by = 0.01),\n       y = dnorm(x, 1, 1)) |> \n  ggplot(aes(x, y)) + geom_line(size = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"Prior on means\")\n\n\n\n\nI usually save the model file in order to avoid having to recompile and sample unless the model specification has changed.\n\n\nm1 <- brm(formula1, \n          prior = priors1,\n          data = d,\n          file = \"../../models/02-m1\")\n\n\n\nLooking at the posterior estimates, we note that the means are similar to the sample means.\n\n\nsummary(m1)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ 0 + condition \n   Data: d (Number of observations: 30) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nconditionA     0.03      0.18    -0.32     0.39 1.00     3986\nconditionB     1.15      0.18     0.79     1.51 1.00     4193\nconditionC     2.04      0.18     1.69     2.37 1.00     3913\n           Tail_ESS\nconditionA     2795\nconditionB     2658\nconditionC     2768\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.57      0.08     0.44     0.74 1.00     3394     2812\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nFor reference, here are the sample means:\n\n\ncondition_means\n\n\n# A tibble: 3 x 3\n  condition   mean    sd\n  <chr>      <dbl> <dbl>\n1 A         0.0321 0.353\n2 B         1.16   0.562\n3 C         1.94   0.578\n\nHowever, stan gives us full posterior distributions, not just point estimates. We can visualize these using the type argument in mcmc_plots().\n\n\nmcmc_plot(m1, type = \"areas\")\n\n\n\n\nWe can extract the population-level effects using fixef(), which is named like this to be consistent with other modelling packages in R. We can get either summaries, or the samples.\n\n\nfixef(m1)\n\n\n             Estimate Est.Error       Q2.5     Q97.5\nconditionA 0.03302576 0.1814484 -0.3152898 0.3900089\nconditionB 1.15011637 0.1805871  0.7891059 1.5103085\nconditionC 2.03947646 0.1756655  1.6853433 2.3745034\n\n\n\nm1_pop <- fixef(m1, summary = FALSE)\n\n\n\nThe samples can be summarized, resulting in the same numbers as above.\n\n\nm1_pop |> \n  as_tibble() |> \n  pivot_longer(everything(),\n               names_to = \"condition\",\n               values_to = \"mean\") |> \n  group_by(condition) |> \n  summarise(estimate = mean(mean),\n            sd = sd(mean),\n            q2.5 = quantile(mean, 0.025),\n            q97.5 = quantile(mean, 0.975))\n\n\n# A tibble: 3 x 5\n  condition  estimate    sd   q2.5 q97.5\n  <chr>         <dbl> <dbl>  <dbl> <dbl>\n1 conditionA   0.0330 0.181 -0.315 0.390\n2 conditionB   1.15   0.181  0.789 1.51 \n3 conditionC   2.04   0.176  1.69  2.37 \n\nHierarchical model\nNow let’s treat the data as if they were clustered, e.g. repeated measures of a three subject in a single condition. If it helps, we can rename the condition variable to subject:\n\n\nd <- d |> select(subject = condition, response) \n\n\n\n\n\nsubject_means <- d |> \n  group_by(subject) |> \n  summarise(mean = mean(response),\n            sd = sd(response))\n\n\n\nWe now want to estimate the population-level mean, averaged over subjects, but we are also interested in the subject-level means. This is a partial pooling model, as opposed to the no-pooling model from above.\n\nIn brms, these are called group-level effects, as they are varying effects for each level of a grouping variable.\nThe formula states that we are predicting repsonse as an average effect, with varying effects for each subject.\n\n\nformula2 <- response ~ 1 + (1 | subject)\n\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{response}_{i}  &\\sim N \\left(\\alpha_{j[i]}, \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for subject j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\] One way to think of this is that the subject means \\(\\alpha_{j}\\) are themselves drawn from a normal distribution, with mean \\(\\mu_{\\alpha}\\) and SD \\(\\sigma_{\\alpha}\\). THis is what makes this a hierarchical problem—subject parameters are random draws from a super-population., and are therefore related, in the sense that they have a commmon distribution. In mathematical terms, the subject parameters are \\(i.i.d\\) and are exchangeable.\n\nThis means that we could change the ordering or the labelling of the subjects, and this would not affect the outcome.\nLet’s see what priors we get for this model.\n\n\nget_prior(formula2, data = d) |> \n  as_tibble() |> select(1:4)\n\n\n# A tibble: 5 x 4\n  prior                    class     coef        group    \n  <chr>                    <chr>     <chr>       <chr>    \n1 \"student_t(3, 0.9, 2.5)\" Intercept \"\"          \"\"       \n2 \"student_t(3, 0, 2.5)\"   sd        \"\"          \"\"       \n3 \"\"                       sd        \"\"          \"subject\"\n4 \"\"                       sd        \"Intercept\" \"subject\"\n5 \"student_t(3, 0, 2.5)\"   sigma     \"\"          \"\"       \n\nWe now have a student_t(3, 0.9, 2.5) prior on the intercept, which is the overall mean, and we have a student_t(3, 0, 2.5) prior on the SD of the subjects’ varying effects around the mean. This is the term \\(\\sigma_{\\alpha}\\). Because SD parameters must be \\(>0\\), \\(\\sigma_{\\alpha}\\) has a half student-t distribution. The parameter sigma is the residual standard deviation.\n\n\nlibrary(patchwork)\n\np_intercept <- tibble(x = seq(-10, 15, by = 0.01),\n       Intercept = dstudent_t(x, 3, 0.9, 2.5)) |> \n  # pivot_longer(c(Intercept, sd), names_to = \"prior\", values_to = \"y\") |> \n  ggplot(aes(x, Intercept)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"Intercept\")\n\np_sd <- tibble(x = seq(0, 15, by = 0.01),\n       sd = dstudent_t(x, 3, 0, 2.5)) |> \n  ggplot(aes(x, sd)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"sigma\")\n\np_intercept + p_sd\n\n\n\n\nUsing the default priors is not a good idea at all here; the priors are too wide. This means that the sampling algorithm will be trying to explore parts of the parameter space where the likelihood is very small. This is very inefficient, and Stan gives us a warning if we try to run this model.\n\n\nm2 <- brm(formula2,\n          data = d,\n          control = list(adapt_delta = 0.9),\n          file = \"../../models/02-m2\")\n\n\n\n\n\nsummary(m2)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ 1 + (1 | condition) \n   Data: d (Number of observations: 30) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~condition (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)     1.42      0.86     0.47     3.64 1.01      733\n              Tail_ESS\nsd(Intercept)     1197\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.95      0.86    -0.93     2.69 1.00      742      692\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.07     0.40     0.69 1.00     1733     1771\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nThe esatimate for the intercept and the SD is very uncertain.\n\n\nmcmc_plot(m2, type = \"areas\")\n\n\n\n\nWe can do better that that, by choosing more informative priors:\n\n\np_intercept <- tibble(x = seq(-10, 15, by = 0.01),\n       Intercept = dnorm(x, 1, 1)) |> \n  ggplot(aes(x, Intercept)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"Intercept\")\n\np_sd <- tibble(x = seq(0, 15, by = 0.01),\n       sd = dstudent_t(x, 3, 0, 1)) |> \n  ggplot(aes(x, sd)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"sigma\")\n\np_intercept + p_sd\n\n\n\n\n\n\npriors3 <- prior(normal(1, 1), class = Intercept) +\n  prior(student_t(3, 0, 1), class = sd)\n\nm3 <- brm(formula2,\n          data = d,\n          prior = priors3,\n          control = list(adapt_delta = 0.9),\n          file = \"../../models/02-m3\")\n\n\n\n\n\nsummary(m3)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ 1 + (1 | subject) \n   Data: d (Number of observations: 60) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)     1.10      0.52     0.46     2.44 1.00     1168\n              Tail_ESS\nsd(Intercept)     1469\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.02      0.52    -0.07     2.08 1.00     1225     1246\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.52      0.05     0.43     0.63 1.00     1991     2231\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nIt isn’t that obvious, but the estimate of the intercept is narrower in model 3.\n\n\nposts <- tibble(name  = str_c(\"m\", 2:3),\n                model = str_c(\"Model \", 2:3)) |>\n  mutate(fit = map(name, get)) |> \n  mutate(post = map(fit, posterior_samples))\n  \n# head(posts)\n\nposts <- posts |> \n  select(-fit) |> \n  unnest(post)\n\nposts_mean <- posts |> \n  pivot_longer(starts_with(\"b_Intercept\"), names_to = \"subject\",\n               values_to = \"value\")\nposts_mean |> \n  ggplot(aes(x = value, y = model)) +\n  stat_halfeye() \n\n\n\n\nThe same is true of the standard deviation of the varying intercepts— in model 3, we have a mean of \\(1.10\\) with a 95% of \\([0.46, 2.44]\\), where in model 2 we have a mean of \\(1.42\\) and a 95% of \\([0.47, 3.64]\\).\nVarying effects\nWe are not just interested in the population-level effect; we want the subject effects too.\nWhile you can get these using the ranef() function (ranef(m3) gives you a summary, you have to set summary = FALSE to get the samples (ranef(m3, summary = FALSE)).\nI really like using tidybayes for this, as it’s functions return tidy data frames.\nIf we want just the varying effects, we can use r_subject[subject] with the placeholer subject. This will be replaced by the subject ID\n\n\nm3 |> \n  spread_draws(r_subject[subject])\n\n\n# A tibble: 12,000 x 5\n# Groups:   subject [3]\n   subject r_subject .chain .iteration .draw\n   <chr>       <dbl>  <int>      <int> <int>\n 1 A          -1.05       1          1     1\n 2 A          -2.29       1          2     2\n 3 A          -0.751      1          3     3\n 4 A          -1.98       1          4     4\n 5 A          -1.70       1          5     5\n 6 A          -1.21       1          6     6\n 7 A          -1.05       1          7     7\n 8 A          -1.15       1          8     8\n 9 A          -0.565      1          9     9\n10 A          -0.888      1         10    10\n# … with 11,990 more rows\n\nThe varying effects are centred at zero. If you want the subjects-specific means, you have to add the population-level estimate.\n\n\nm3 %>%\n  spread_draws(b_Intercept, r_subject[subject]) |> \n  median_qi(subject_mean = b_Intercept + r_subject) \n\n\n# A tibble: 3 x 7\n  subject subject_mean .lower .upper .width .point .interval\n  <chr>          <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1 A             0.0482 -0.177  0.276   0.95 median qi       \n2 B             1.15    0.932  1.38    0.95 median qi       \n3 C             1.92    1.69   2.14    0.95 median qi       \n\n\n\np3_shrinkage <- m3 |> \n  spread_draws(b_Intercept, r_subject[subject]) |> \n  median_qi(subject_mean = b_Intercept + r_subject) |> \n  ggplot(aes(y = subject, x = subject_mean, \n             color = subject)) +\n  geom_pointinterval(aes(xmin = .lower, xmax = .upper), point_size = 4) +\n  scale_color_brewer(type = \"qual\")\np3_shrinkage \n\n\n\n\n\n\np3_shrinkage +\n    geom_point(aes(mean, subject), \n             data = subject_means, \n             size = 2, color = \"black\") +\n  ggtitle(\"Hierarchical shrinkage\")\n\n\n\n\nPlotting the no-pooling estimates alongside the pooled estimates reveals that the partial-pooling estimates are less extreme that the no-pooling ones. This is due to the fact that the estimates are drawn to the overall mean, and is known as shrinkage.\nMultilevel example\nNow we will simulate data from a pre-post treatment study. The treatment is applied to every subject, so is what is commonly referred to as a within-subject variable.\nThis function generates data for n_subjects subjects in two conditions, with the following parameters:\n\n\nparams <- tribble(~Parameter, ~`Default value`, ~Desccription,\n                  \"a\", 3.5, \"average pre-treatment effect (intercepts)\",\n                  \"b\", -1, \"average difference between pre and post\",\n                  \"sigma_a\", 1, \"std dev in intercepts\",\n                  \"sigma_b\", 0.8, \"std dev in differences (slopes)\",\n                  \"rho\", -0.7, \"correlation between intercepts and slopes\",\n                  \"n_subject\", 10, \"no. subjects\",\n                  \"n_trials\", 20, \"no. trials per subject per condition\",\n                  \"sigma\", 0.5, \"residual standard deviation\") \nparams |> \n    kableExtra::kbl() |> \n    kableExtra::kable_paper(\"hover\", full_width = T)\n\n\n\nParameter\n\n\nDefault value\n\n\nDesccription\n\n\na\n\n\n3.5\n\n\naverage pre-treatment effect (intercepts)\n\n\nb\n\n\n-1.0\n\n\naverage difference between pre and post\n\n\nsigma_a\n\n\n1.0\n\n\nstd dev in intercepts\n\n\nsigma_b\n\n\n0.8\n\n\nstd dev in differences (slopes)\n\n\nrho\n\n\n-0.7\n\n\ncorrelation between intercepts and slopes\n\n\nn_subject\n\n\n10.0\n\n\nno. subjects\n\n\nn_trials\n\n\n20.0\n\n\nno. trials per subject per condition\n\n\nsigma\n\n\n0.5\n\n\nresidual standard deviation\n\n\n\n\nShow code\n\nsimulate_treatment <- function(a = 3.5,\n                              b = -1,\n                              sigma_a = 1,\n                              sigma_b = 0.8,\n                              rho = -0.7,\n                              n_subjects = 10,\n                              n_trials = 20,\n                              sigma = 0.5) {\n\n    # Ccombine the terms\n    mu <- c(a, b)\n    cov_ab <- sigma_a * sigma_b * rho\n    SD  <- matrix(c(sigma_a^2, cov_ab,\n                       cov_ab, sigma_b^2), ncol = 2)\n\n   #  sigmas <- c(sigma_a, sigma_b)          # standard deviations\n   #  rho <- matrix(c(1, rho,             # correlation matrix\n   #                 rho, 1), nrow = 2)\n   # \n   # # now matrix multiply to get covariance matrix\n   # SD <- diag(sigmas) %*% rho %*% diag(sigmas)\n\n    varying_effects <-\n        MASS::mvrnorm(n_subjects, mu, SD) |>\n        # as_tibble(.name_repair = \"unique\") |>\n        data.frame() |>\n        purrr::set_names(\"a_j\", \"b_j\")\n\n    d_linpred <-\n        varying_effects |>\n        mutate(subject  = 1:n_subjects) |>\n        expand(nesting(subject, a_j, b_j), post = c(0, 1)) |>\n        mutate(mu = a_j + b_j * post,\n               sigma = sigma) |>\n        mutate(treatment = ifelse(post == 0, \"pre\", \"post\"),\n               treatment = factor(treatment, levels = c(\"pre\", \"post\")))\n\n    d <- d_linpred |>\n        slice(rep(1:n(), each = n_trials)) |>\n        mutate(response = rnorm(n = n(), mean = mu, sd = sigma))\n\n   d\n}\n\n\n\n\n\nShow code\n\nplot_linpred <- function(d, violin = FALSE) {\n  \n  d_linpred <- d |>\n  group_by(subject, treatment) |> distinct(mu, .keep_all = TRUE)\n  \n  p <- d_linpred |>\n    ggplot(aes(x = treatment, y = mu))\n  \n  if (isTRUE(violin)) {\n  p <- p + \n      geom_violin(aes(x = treatment, y = response,\n                          fill = treatment), \n                  alpha = 0.5,\n                  data = d) +\n      geom_jitter(aes(x = treatment, y = response,\n                          color = treatment), \n                  width = 0.1, size = 2,\n                  data = d)\n  }\n  \n  p <- p +\n    geom_line(aes(group = 1), color = \"#8B9DAF\", size = 1, linetype = 3) +\n    geom_point(aes(fill = treatment), \n               shape = 21, \n               colour = \"black\", \n               size = 4, \n               stroke = 2) +\n    scale_fill_brewer(type = \"qual\") +\n    scale_color_brewer(type = \"qual\") +\n    coord_cartesian(ylim = c(0, 8)) +\n    ylab(\"Response\") +\n    theme(legend.position = \"none\",\n          axis.ticks.x    = element_blank()) +\n    facet_wrap(~ subject) +\n  ggtitle(\"Linear predictor\")\n  \n  p\n}\n\n\n\n\n\nset.seed(52)\nd1 <- simulate_treatment(n_subjects = 5)\n\n\n\n\n\nplot_linpred(d1)\n\n\n\n\n\n\nplot_linpred(d1, violin = T)\n\n\n\n\n\n\nset.seed(52)\nd2 <- simulate_treatment(n_subjects = 5, \n                        sigma_a = 1.2, \n                        sigma_b = 0.2, \n                        rho = -0.7)\n\nplot_linpred(d2, violin = F)\n\n\n\n\n\n\nd <- simulate_treatment(n_subjects = 10, n_trials = 50)\nplot_linpred(d, violin = F)\n\n\n\n\n\\[\\begin{align*}\n\\text{response}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i         & = \\alpha_{\\text{subject}_i} + \\beta_{\\text{subject}_i} \\text{treatment}_i \\\\\n\\begin{bmatrix} \\alpha_\\text{subject} \\\\ \\beta_\\text{cafe} \\end{bmatrix} & \\sim \\text{MVNormal} \\left (\\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}, \\mathbf{S}  \\right ) \\\\\n\\mathbf S     & = \\begin{bmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{bmatrix} \\mathbf R \\begin{bmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{bmatrix} \\\\\n\\alpha        & \\sim \\operatorname{Normal}(0, 10) \\\\\n\\beta         & \\sim \\operatorname{Normal}(0, 10) \\\\\n\\sigma        & \\sim \\operatorname{HalfCauchy}(0, 1) \\\\\n\\sigma_\\alpha & \\sim \\operatorname{HalfCauchy}(0, 1) \\\\\n\\sigma_\\beta  & \\sim \\operatorname{HalfCauchy}(0, 1) \\\\\n\\mathbf R     & \\sim \\operatorname{LKJcorr}(2),\n\\end{align*}\\]\n\n\nget_prior(response ~ treatment + (treatment | subject),\n          data = d) |> \n  as_tibble() |> select(1:4)\n\n\n# A tibble: 10 x 4\n   prior                    class     coef            group    \n   <chr>                    <chr>     <chr>           <chr>    \n 1 \"\"                       b         \"\"              \"\"       \n 2 \"\"                       b         \"treatmentpost\" \"\"       \n 3 \"lkj(1)\"                 cor       \"\"              \"\"       \n 4 \"\"                       cor       \"\"              \"subject\"\n 5 \"student_t(3, 3.2, 2.5)\" Intercept \"\"              \"\"       \n 6 \"student_t(3, 0, 2.5)\"   sd        \"\"              \"\"       \n 7 \"\"                       sd        \"\"              \"subject\"\n 8 \"\"                       sd        \"Intercept\"     \"subject\"\n 9 \"\"                       sd        \"treatmentpost\" \"subject\"\n10 \"student_t(3, 0, 2.5)\"   sigma     \"\"              \"\"       \n\n\n\nlibrary(rethinking)\n\nn_sim <- 1e5\n\nset.seed(13)\nr_1 <- \n  rlkjcorr(n_sim, K = 2, eta = 1) %>%\n  as_tibble()\n\nset.seed(13)\nr_2 <- \n  rlkjcorr(n_sim, K = 2, eta = 2) %>%\n  as_tibble()\n\nset.seed(13)\nr_4 <- \n  rlkjcorr(n_sim, K = 2, eta = 4) %>%\n  as_tibble()\n\n\n\n\n\nggplot(data = r_1, aes(x = V2)) +\n  geom_density(color = \"transparent\", fill = \"#5e81ac\", alpha = 2/3) +\n  geom_density(data = r_2,\n               color = \"transparent\", fill = \"#a3be8c\", alpha = 2/3) +\n  geom_density(data = r_4,\n               color = \"transparent\", fill = \"#bf616a\", alpha = 2/3) +\n  geom_text(data = tibble(x = c(.83, .62, .46),\n                          y = c(.54, .74, 1),\n                          label = c(\"eta = 1\", \"eta = 2\", \"eta = 4\")),\n            aes(x = x, y = y, label = label),\n            color = \"#A65141\", family = \"Courier\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"correlation\")\n\n\n\n\n\n\nfit1_prior <- brm(response ~ treatment + (treatment | subject),\n            prior = prior(normal(0, 10), class = b),\n            data = d,\n            sample_prior = \"only\",\n            file = \"../../models/02-fit1-prior\")\n\nfit1 <- brm(response ~ treatment + (treatment | subject),\n            prior = prior(normal(0, 10), class = b),\n            data = d,\n            file = \"../../models/02-fit1\")\n\n\n\n\n\nsummary(fit1)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ treatment + (treatment | subject) \n   Data: d (Number of observations: 1000) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 10) \n                             Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                    0.84      0.23     0.53     1.40\nsd(treatmentpost)                0.83      0.24     0.50     1.40\ncor(Intercept,treatmentpost)    -0.63      0.21    -0.91    -0.09\n                             Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                1.00     1399     1558\nsd(treatmentpost)            1.00     1268     1742\ncor(Intercept,treatmentpost) 1.00     1740     2081\n\nPopulation-Level Effects: \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept         3.39      0.28     2.83     3.93 1.00      959\ntreatmentpost    -0.84      0.26    -1.37    -0.33 1.00     1391\n              Tail_ESS\nIntercept         1280\ntreatmentpost     1769\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.49      0.01     0.47     0.52 1.00     3066     2416\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nmcmc_plot(fit1_prior)\n\n\n\n\n\n\nmcmc_plot(fit1)\n\n\n\n\n\n\npp_check(fit1_prior, type = \"dens_overlay_grouped\", group = \"treatment\")\n\n\n\n\n\n\npp_check(fit1, type = \"dens_overlay_grouped\", group = \"treatment\")\n\n\n\n\n\n\npp_check(fit1, nsamples = 100, type ='stat', stat='median')\n\n\n\n\n\n\ngrid <- d |> \n  modelr::data_grid(subject, treatment)\n\ngrid\n\n\n# A tibble: 20 x 2\n   subject treatment\n     <int> <fct>    \n 1       1 pre      \n 2       1 post     \n 3       2 pre      \n 4       2 post     \n 5       3 pre      \n 6       3 post     \n 7       4 pre      \n 8       4 post     \n 9       5 pre      \n10       5 post     \n11       6 pre      \n12       6 post     \n13       7 pre      \n14       7 post     \n15       8 pre      \n16       8 post     \n17       9 pre      \n18       9 post     \n19      10 pre      \n20      10 post     \n\nfits <- grid %>%\n  add_fitted_draws(fit1)\n\npreds <- grid %>%\n  add_predicted_draws(fit1)\n\nd %>%\n  ggplot(aes(y = treatment, x = response)) +\n  stat_interval(aes(x = .prediction), data = preds) +\n  stat_pointinterval(aes(x = .value), data = fits, .width = c(.66, .95), \n                     position = position_nudge(y = -0.3)) +\n  geom_point() +\n  scale_color_brewer()\n\n\n\n\n\n\nconditional_effects(fit1, re_formula = NA)\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-05-28-multilevelmodels/distill-preview.png",
    "last_modified": "2021-05-29T02:00:30+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-24-walkthrough-brms/",
    "title": "An Introduction to brms",
    "description": "Using `brms` for parameter estimation: A walkthrough",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": "https://github.com/awellis"
      }
    ],
    "date": "2021-05-23",
    "categories": [
      "wokflow",
      "data analysis"
    ],
    "contents": "\n\nContents\nGenerate data\nProbabilistic model\nLinear model\nPrior distributions\n\nPrior predictive distribution\nPrior predictive checks\n\nPosterior inference\nParameter estimates\nConditional means\nPosterior predictive check\nAll in one\n\n\n\nI am using the native pipe operator, which is new to R 4.10. This pipe operator is written as a | followed by a >. In this document, the operator is printed as |>, due to the fact that I am using font ligatures. If the pipe doesn’t work for you, simply replace it with the older pipe %>%.\n\n\n\nlibrary(tidyverse)\nlibrary(brms)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nIn this post, I’ll show how to use brms to infer the means of two independent normally distributed samples. I’ll try to follow the steps illustrated in the previous post on a principled Bayesian workflow.\nGenerate data\nFirst, we’ll generate two independent normally distributed samples. These will correspond to two levels of a grouping variable, so let’s call them group A and group B.\nGroup A will have a mean \\(\\mu_A = 20\\) and a standard deviation \\(\\sigma_A = 2\\), whereas group B have have the parameters \\(\\mu_B = 16\\) and \\(\\sigma_B = 1.5\\).\n\n\nmean_a <- 20.0\nsigma_a <- 2.0\n\nmean_b <- 16.0\nsigma_b <- 1.5\n\ntrue_params <- tribble(~Group, ~Mean, ~SD,\n                  \"A\", mean_a, sigma_a,\n                  \"B\", mean_b, sigma_b) \ntrue_params |> \n    kableExtra::kbl() |> \n    kableExtra::kable_paper(\"hover\", full_width = T)\n\n\n\nGroup\n\n\nMean\n\n\nSD\n\n\nA\n\n\n20\n\n\n2.0\n\n\nB\n\n\n16\n\n\n1.5\n\n\nWe now draw 10 observations for each group.\n\n\nN <- 10\n\nset.seed(12)\nd <- tibble(A = rnorm(N, mean_a, sigma_a),\n            B = rnorm(N, mean_b, sigma_b))\nd <- d |>\n  pivot_longer(everything(), names_to = \"group\",\n                values_to = \"score\") |> \n  mutate(group = as_factor(group)) |> \n  arrange(group)\n\n\n\nSince we know the true values that generated the data, we know whether we will be able to successfully recover them. Of course, the sample means and standard deviations will differ slightly from the true values.\n\n\nfuns <- list(mean = mean, median = median, sd = sd)\nd |>\n  group_by(group) |>\n  summarise(across(everything(), funs, .names = \"{.fn}\"))\n\n\n# A tibble: 2 x 4\n  group  mean median    sd\n  <fct> <dbl>  <dbl> <dbl>\n1 A      19.1   19.1  2.00\n2 B      15.7   15.7  1.11\n\nProbabilistic model\nWe assume the data are conditionally normally distributed\n\\[ y_i \\sim \\mathcal{N}(\\mu_{[j]}, \\sigma_{[j]}) \\] \\[ \\text{for J = 1, 2} \\]\nWe will initially assume that the two groups have equal standard deviations (SD), so that we need only estimate one common SD parameter. We therefore need to estimate three parameters in total, \\(\\mu_a, \\mu_b, \\sigma\\) (you can allow both mean and standard deviation to vary in assignment 1).\nLinear model\nUsing a linear model, we have several possibilities for choosing our contrast coding. We will use treatment coding, in which we choose one of the groups as reference category. This will be represented by the intercept. The other group will not be estimated directly. Instead, the second parameter will represent the difference between this group and the reference category.\nWe can check the levels of the grouping variable. The first levels will be chose as the reference group.\n\n\nlevels(d$group)\n\n\n[1] \"A\" \"B\"\n\nAnother possibility is to omit the intercept, and then just estimate both group means independently.\n\nFor parameter estimation, the difference between the two approaches will affect the choice of priors, but not the conclusions we can draw. Once we have the posterior distributions, we can compute any quantity of interest directly from the posterior samples. The choice of contrast coding will become important later, when we look at model comparisons.\nFor the first approach, we use the R formula\n\n\nscore ~ 1 + group\n\n\nscore ~ 1 + group\n\n# or eqivalently\nscore ~ group\n\n\nscore ~ group\n\nFor the second parameterization, we write\n\n\nscore ~ 0 + group\n\n\nscore ~ 0 + group\n\n# or eqivalently\nscore ~ group - 1\n\n\nscore ~ group - 1\n\nPrior distributions\nWe can check which for which parameters we need to set priors, and what the default priors are, using the get_prior() function.\n\n\nget_prior(score ~ group, data = d)\n\n\n                   prior     class   coef group resp dpar nlpar bound\n                  (flat)         b                                   \n                  (flat)         b groupB                            \n student_t(3, 16.9, 2.5) Intercept                                   \n    student_t(3, 0, 2.5)     sigma                                   \n       source\n      default\n (vectorized)\n      default\n      default\n\nThe output doesn’t look very appealing, so we can show just the first four columns:\n\n\nget_prior(score ~ group, data = d) |> \n  tibble() |> select(1:4)\n\n\n# A tibble: 4 x 4\n  prior                     class     coef     group\n  <chr>                     <chr>     <chr>    <chr>\n1 \"\"                        b         \"\"       \"\"   \n2 \"\"                        b         \"groupB\" \"\"   \n3 \"student_t(3, 16.9, 2.5)\" Intercept \"\"       \"\"   \n4 \"student_t(3, 0, 2.5)\"    sigma     \"\"       \"\"   \n\nThe three parameters are groupB, represents the difference between group B and the reference category, Intercept, which represents group A, and sigma, the common standard deviation.\nBoth Intercept and sigma are given Student-t priors. The first parameter of this distribution can be considered as a “normality” parameter—the higher this is, the more normal the distribution looks. The prior on the intercept has a mean of 16.9, which is based on the median of the response variable (median(d$score)) and a standard devation of 2.5. The default priors are guesses to ensure that the posterior is in the raight range, while making it unlikely that the prior biases the inferences.\nSomething that is not apparent is that the prior on sigma is actually a folded Student-t distribution—this means that the distribution is folded in half, because the parameter sigma is constrained to be positive (a standard deviation must \\(>0\\).\nThe prior on the groupB parameter is flat. This is basically never a good idea—you should always choose your own prior, instead of using the default flat prior.\n\nThe same goes for the other parameters—you should never blindly accept the defaults. Of course, having these defaults is very useful if you want to get up and running, or if you want to quickly try out a model. However, they should be considered the starting point, and should be replaced by priors based on prior predictive checks.\nFor the second parameterization, we get\n\n\nget_prior(score ~ 0 + group, data = d)\n\n\n                prior class   coef group resp dpar nlpar bound\n               (flat)     b                                   \n               (flat)     b groupA                            \n               (flat)     b groupB                            \n student_t(3, 0, 2.5) sigma                                   \n       source\n      default\n (vectorized)\n (vectorized)\n      default\n\nHere, we get the same statndard deviation parameter, but instead of an intercept we get two parameters, one for each level of the grouping variable. Both have flat priors.\n\nOne important difference between the two is that for the second parameterization, both levels are treated in the same manner, whereas for the first approach, the reference get a prior, and the non-reference category is coded as Intercept + groupB. There the mean of group B will be estimated with more uncertainty that that of group A. While this makes sense for hypothesis testing, for estimation this is questionable. McElreath (2020) generally recommends the second approach.\n\nWe will ignore McElreath’s advice for now, and estimate mean of group B as Intercept + groupB.\nSince we already know from the summary above that the difference between groups cannot tbe very large, we set a normal(0, 4) on the group difference. This expresses the belief that we are about 95% certain that the parameter will lie between \\(-8\\) and \\(8\\)\nWe can use the brms function prior() to do this.\n\n\nprior(normal(0, 4), class = b)\n\n\nb ~ normal(0, 4)\n\n\nThis may not be a particularly good prior. We are merely illustrating the wokflow here. This prior should not have much of an influence on the posterior.\nThe priors on the intercept and and group difference look like this:\n\n\nlibrary(patchwork)\n\np_intercept <- tibble(x = seq(0, 35, by = 0.01),\n       y = dstudent_t(x, 3, 16.9, 2.5)) |> \n  ggplot(aes(x, y)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"Intercept\")\n\np_groupB <- tibble(x = seq(-10, 10, by = 0.01),\n       y = dnorm(x, 0, 4)) |> \n  ggplot(aes(x, y)) + geom_line(size = 2) +\n  ylab(\"\") + xlab(\"\") +\n  ggtitle(\"groupB\")\n\np_intercept + p_groupB\n\n\n\n\nPrior predictive distribution\nIn order to get the prior predictive distribution, we can first sample from the prior distributions using the sample_prior argument set to \"only\". If we do this, we are running the same model that we will later use to obtain the posterior distribution, but we are ignoring the data.\n\nThe file argument can be used to store the output of the brm() function on disk, so that it won’t be run again unless the model specification changes.\n\n\nm1_prior <- brm(score ~ group, \n               prior = prior(normal(0, 4), class = b),\n               data = d, \n               sample_prior = \"only\", \n               file = \"models/m1_prior\")\n\n\n\nThis model will do three things: 1) provide prior distributions of the parameters, 2) provide distributions of the conditional means, i.e. the values of the linear predictor and 3) provide samples from the prior predictive distribution.\nWe can visualize the distribution of parameter values that our model expects using the mcmc_plots() function.\n\n\nmcmc_plot(m1_prior)\n\n\n\n\nThese distributions just reflect the prior distributions, i.e. they are sampled from each parameter’s prior distribution. It is very helpful, though, to plot the conditional means, i.e. the expected means conditioned on group membership.\n\nTo be precise, conditional_effects() plots the expected means of the prior predictive distribution (prior because we are only sampling from the prior in this model).\n\n\nconditional_effects(m1_prior)\n\n\n\n\nBoth groups are expected to have similar means, because that is what we expressed with our prior distribution on the group difference.\nPrior predictive checks\nWe can then add additional variance by incorporating the residual error. This can be achieved by using the posterior_predict() function and then processing the output; however, it is often far simpler to use the built-in function pp_check() (the pp stand for posterior predictive). This function cab perform a variety of posterior predictive checks; here we are simply plotting the density of the data (\\(y\\)) along with densitites obtained from generated data (\\(y_{rep}\\)).\n\nIf we sample from the posterior, then pp_check() performs posterior predictive checks. If we sample from the prior only, then pp_check() performs prior predictive checks.\n\nThis plot can give us a good idea of what kind of data our model expects, and we can compare those to the actual data obtained\n\n\npp_check(m1_prior)\n\n\n\n\nWe can also group by our grouping variable to compare the generated data separately by group.\n\n\npp_check(m1_prior, type = \"dens_overlay_grouped\", group = \"group\")\n\n\n\n\nPosterior inference\nIf we are happy with our model, we can sample from the posterior, using the same model from above, but ommitting the sample_prior argument. As above, brms generated Stan code, which is then compiled to C++. Once the model is compiled, Stan runs 4 independent Markov chains, each of which will explore the posterior distribution. The number of chains can be specified, but it is rarely necesarry to change the default setting of 4.\n\nIt is a good idea to use as many cores as possible. Modern computers have multi-core processors. This means that Stan will make use of as many cores as it can, and run the chains in parallel. This will result in a huge speed-up. You can use the argument cores = parallel::detectCores() inside brm() to set this. It advisable to set this in the R options, so that you do have to do this every time you call brm().\n\n\n\nm1 <- brm(score ~ group, \n          prior = prior(normal(0, 4), class = b),\n          data = d, \n          file = \"models/m1\")\n\n\n\nBefore we look at the parameter estimates, it essential to check that the 4 chains have converged, i.e. that they are sampling from the same posterior. Calling the plot() method on the fitted object will plot traceplots (on the right of the plot), which are the estimates (on the y axis) plotted against the sample number.\n\n\nplot(m1)\n\n\n\n\nAnother way of getting these is with the function mcmc_trace() from the bayesplot package.\n\n\nlibrary(bayesplot)\nmcmc_trace(m1)\n\n\n\n\nThe plots for each parameter show the 4 chains (in different shades of blue). They should not be easily distinguishable from each other, and should resemble a “fat hairy caterpillar.”\nApart from visual inspection, we can check for convergence of the chains by looking at the Rhat values in the output. There is one for each estimated parameter, and these values should be approximately \\(1.0\\), and \\(> 1.05\\). The Rhat statistic measures the ratio of the average variance of samples within each chain to the variance of the pooled samples across chains. If these values are \\(1.0\\), this means that the chains have mixed well and are sampling from the same posterior.\n\n\nsummary(m1)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: score ~ group \n   Data: d (Number of observations: 20) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    18.99      0.53    17.94    20.02 1.00     3264     2501\ngroupB       -3.24      0.74    -4.68    -1.72 1.00     3224     2541\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.70      0.30     1.24     2.40 1.00     3104     2737\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nWe can now look at the estimated parameters. Here, we get Population-Level Effects and Family Specific Parameters. The population-level effects are our intercept and group difference, the fFamily-specific parameter is the residual standard deviation. For each parameter we are shown the mean of the posterior distribution (Estimate), the standard deviation of the posterior distribution (Est.Error) as well as two-sided 95% credible intervals(l-95% CI and u-95% CI) based on quantiles. The Bulk and Tail ESS (expected sample size) are estimates of how many independent draws would contain the same amount of information as the correlated draws of the posterior (Markov chains obtain correlated draws).\nParameter estimates\nThe three parameters are Intercept, groupB and sigma. The latter represents the stndard deviation, which according to our model is not allowd to vary between groups (our model is thus mis-specified, as we know that sigma differs between groups.) The posterior is mean is 1.7, with a 95% CI of [1.24, 2.4]. We are thus 95% certain the the standard deviation lies within that interval.\nIntercept and groupB reprsent the expected mean of the reference group, which is A in this case, and the difference between groups, respectively.\nThe intercept has a mean of 18.99, with a 95% CI of [17.94, 20.02], and the difference between groups has a mean of -3.24 with a 95% CI of [-4.68, 1.72].\n\nThe 95% CIs obtained here are credible intervals, i.e. summaries of the posterior distributions based on quantiles. They are NOT confidence intervals.\nThese are merely summaries of the posterior distributions. It is also very important to look at the full posterior distributions. These can be plotted with the function mcmc_plot().\n\n\nmcmc_plot(m1)\n\n\n\n\nWe can also choose which parameters to plot:\n\n\nmcmc_plot(m1, \"b_groupB\")\n\n\n\n\nConditional means\nA simple way to obtain the predicted conditional means is to use the the add_fitted_draws() from the tidybayes package.\n\n\nlibrary(tidybayes)\n\n\n\nThis requires a grid of values for which we want the conditional means. In the case we use the data_grid() function from the modelr package to create this.\n\n\ngrid <- d |> \n  modelr::data_grid(group)\n\ngrid\n\n\n# A tibble: 2 x 1\n  group\n  <fct>\n1 A    \n2 B    \n\nWe can the use add_fitted_draws() to obtain the values of the linear predictor, which in this case will be either the Intercept for group A, or Intercept + groupB for group B.\n\n\ngrid |> \n  add_fitted_draws(m1)\n\n\n# A tibble: 8,000 x 6\n# Groups:   group, .row [2]\n   group  .row .chain .iteration .draw .value\n   <fct> <int>  <int>      <int> <int>  <dbl>\n 1 A         1     NA         NA     1   19.2\n 2 A         1     NA         NA     2   19.5\n 3 A         1     NA         NA     3   19.7\n 4 A         1     NA         NA     4   18.1\n 5 A         1     NA         NA     5   18.4\n 6 A         1     NA         NA     6   18.8\n 7 A         1     NA         NA     7   19.1\n 8 A         1     NA         NA     8   19.2\n 9 A         1     NA         NA     9   18.7\n10 A         1     NA         NA    10   18.5\n# … with 7,990 more rows\n\nThese can then be plotted using the stat_pointinterval() function, which takes a .width argument to specify the width of the credible interval.\n\n\ngrid |> \n  add_fitted_draws(m1) |> \n  ggplot(aes(x = .value, y = group)) +\n  stat_pointinterval(.width = c(.66, .95))\n\n\n\n\nPosterior predictive check\nSimilarly to above, we can use pp_check(), which will now perform psterior predictive check (because we have sampled from the posterior).\n\n\npp_check(m1)\n\n\n\n\n\n\npp_check(m1, type = \"dens_overlay_grouped\", group = \"group\")\n\n\n\n\nIt is apparent the while our model can adequately represent the shape of the data, the predictions vary quite a lot, which is due to there not being enough data (this is only a toy model, after all).\nAll in one\nUsing the functions from the tidybayes package, we can plot the conditional exptected means, the posterior predictions for the data along with the actual data, all in one plot.\n\n\nfits <- grid %>%\n  add_fitted_draws(m1)\n\npreds <- grid %>%\n  add_predicted_draws(m1)\n\nd %>%\n  ggplot(aes(y = group, x = score)) +\n  stat_interval(aes(x = .prediction), data = preds) +\n  stat_pointinterval(aes(x = .value), data = fits, .width = c(.66, .95), position = position_nudge(y = -0.3)) +\n  geom_point() +\n  scale_color_brewer()\n\n\n\n\nThe blue band shows the posterior predictive density for new data (what data does our model predict?), the black dots within the blue bands show the actual data points, and the intervals underneath show the expected conditional means (values of the linear predictor).\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd Edition. 2nd ed. CRC Press. http://xcelab.net/rm/statistical-rethinking/.\n\n\n\n\n",
    "preview": "posts/2021-05-24-walkthrough-brms/walkthrough-brms_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-05-27T15:57:57+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-22-principled-workflow/",
    "title": "A Principled Bayesian Workflow",
    "description": "Steps in Bayesian Data Analysis",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": "https://github.com/awellis"
      }
    ],
    "date": "2021-05-22",
    "categories": [
      "wokflow",
      "data analysis"
    ],
    "contents": "\nThe following figure illustrates the steps that are ideally involved in data analysis. Whereas traditional approaches often combine inference and hypothesis testing, and consist of applying off-the-shelf methods, data analysis involves many more steps.\n\n\n\nStarting at the beginning, we gather all the knowledge we habe about our data analysis problem. This includes deciding which data to collect, which hypotheses to formulate, quantifying our prior knowledge about our parameters.\nFrom this we formulate a generative model, which is a joint probability model of the data and all parameters.\nOnce we have this, we can perform prior predictve checks. This will inform us about the data our model expects to see, and can tell if our models make sense. If the model makes nonsensical predictions, it might have to be revised.\nWe can can then simulate data from our model using a set of known parameters, and use these data in order to recover the parameters. This is an important step when using complex models, as this will tell us whether our model can recover parameters. If our model fails to do so, it needs revising.\nOnce we have gathered data, we can fit our model to the data by applying Bayes theorem. This will gives a joint posterior distribution of all the parameters.\nUsing posterior predictive checks, we can investigate whether our model can capture patterns n the data. This is an important step in deciding wtether a model is mis-specified.\nAt this point, we may decide to revise our model, thus completing the loop.\nIf we are happy that the model captures all relevant aspects of the data, we can use/interpret the posterior estimates, or we can perform model comparison.\nWe can compare several candidate models using posterior predictive checks or approximate out-of -sample predictive accuracy.\nHypothesis testing is a form of model comparison. Bayes factors can quantify relative evidence for one model over another.\n\n\n\n",
    "preview": "posts/2021-05-22-principled-workflow/../../images/principled-bayesian-workflow.png",
    "last_modified": "2021-05-22T23:54:58+02:00",
    "input_file": {},
    "preview_width": 2104,
    "preview_height": 1526
  },
  {
    "path": "posts/2021-05-21-zoom/",
    "title": "Zoom links",
    "description": "Course dates and Zoom links.",
    "author": [
      {
        "name": "Andrew Ellis",
        "url": {}
      }
    ],
    "date": "2021-05-21",
    "categories": [],
    "contents": "\nFriday mornings\nMeeting ID: 644 5562 5717\nPasscode: 879219\nMay 21, 2021 08:15\nMay 28, 2021 08:15\nJun 4, 2021 08:15\n🔗 Join Zoom Meeting\nSaturday morning and afternoon\nMeeting ID: 638 6457 0235\nPasscode: 888908\nMay 29, 2021 09:15\n🔗 Join Zoom Meeting\n\n\n\n",
    "preview": {},
    "last_modified": "2021-05-21T01:31:45+02:00",
    "input_file": {}
  }
]
